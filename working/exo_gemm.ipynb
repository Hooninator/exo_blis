{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-by-step GEMM implementation in EXO. With some very rough documentation. ##\n",
    "##### Author: Julian Bellavita, UC Berkeley #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from exo import *\n",
    "from exo.libs.memories import DRAM_STATIC\n",
    "from exo.platforms.x86 import *\n",
    "from exo.syntax import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def print_output(fn):\n",
    "    out = fn.c_code_str()\n",
    "    print(\"void sgemm_kernel_avx512_1x4( c_code_str_Context *ctxt, int_fast32_t K, float* A, float* B, float* C )\")\n",
    "    print(out.split(\"void sgemm_kernel_avx512_1x4( c_code_str_Context *ctxt, int_fast32_t K, float* A, float* B, float* C )\")[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Initial sgemm function\n",
    "\"\"\"\n",
    "@proc\n",
    "def SGEMM(M: size, N: size, K: size, A: f32[M, K], B: f32[K, N], C: f32[M, N]):\n",
    "    assert M >= 1\n",
    "    assert N >= 1\n",
    "    assert K >= 1\n",
    "    assert stride(A, 1) == 1\n",
    "    assert stride(B, 1) == 1\n",
    "    assert stride(C, 1) == 1\n",
    "\n",
    "    for k in par(0, K):\n",
    "        for i in par(0, M):\n",
    "            for j in par(0, N):\n",
    "                C[i, j] += A[i, k]*B[k, j]\n",
    "\n",
    "#print_output(SGEMM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Define kernel constants\n",
    "VEC_W = 16\n",
    "\n",
    "M_REG_BLK = 6\n",
    "N_REG_BLK = (4 * VEC_W)\n",
    "\n",
    "M_L1_FAC = 44\n",
    "N_L1_FAC = 1\n",
    "\n",
    "M_L1_BLK = M_REG_BLK * M_L1_FAC\n",
    "N_L1_BLK = N_REG_BLK * N_L1_FAC\n",
    "K_L1_BLK = 512\n",
    "\n",
    "basic_kernel_Mx4 = {}\n",
    "sgemm_kernel_avx512_Mx4 = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#include <stdint.h>\n",
      "#include <stdbool.h>\n",
      "\n",
      "// Compiler feature macros adapted from Hedley (public domain)\n",
      "// https://github.com/nemequ/hedley\n",
      "\n",
      "#if defined(__has_builtin)\n",
      "#  define EXO_HAS_BUILTIN(builtin) __has_builtin(builtin)\n",
      "#else\n",
      "#  define EXO_HAS_BUILTIN(builtin) (0)\n",
      "#endif\n",
      "\n",
      "#if EXO_HAS_BUILTIN(__builtin_assume)\n",
      "#  define EXO_ASSUME(expr) __builtin_assume(expr)\n",
      "#elif EXO_HAS_BUILTIN(__builtin_unreachable)\n",
      "#  define EXO_ASSUME(expr) \\\n",
      "      ((void)((expr) ? 1 : (__builtin_unreachable(), 1)))\n",
      "#else\n",
      "#  define EXO_ASSUME(expr) ((void)(expr))\n",
      "#endif\n",
      "\n",
      "typedef struct c_code_str_Context { \n",
      "\n",
      "} c_code_str_Context;\n",
      "\n",
      "\n",
      "// basic_kernel_4x4(\n",
      "//     K : size,\n",
      "//     A : f32[4,K]  @DRAM,\n",
      "//     B : f32[K,64]  @DRAM,\n",
      "//     C : f32[4,64]  @DRAM\n",
      "// )\n",
      "void basic_kernel_4x4( c_code_str_Context *ctxt, int_fast32_t K, float* A, float* B, float* C );\n",
      "\n",
      "\n",
      "static int _floor_div(int num, int quot) {\n",
      "  int off = (num>=0)? 0 : quot-1;\n",
      "  return (num-off)/quot;\n",
      "}\n",
      "\n",
      "static int8_t _clamp_32to8(int32_t x) {\n",
      "  return (x < -128)? -128 : ((x > 127)? 127 : x);\n",
      "}\n",
      "\n",
      "#include <stdio.h>\n",
      "#include <stdlib.h>\n",
      "\n",
      "\n",
      "// basic_kernel_4x4(\n",
      "//     K : size,\n",
      "//     A : f32[4,K]  @DRAM,\n",
      "//     B : f32[K,64]  @DRAM,\n",
      "//     C : f32[4,64]  @DRAM\n",
      "// )\n",
      "void basic_kernel_4x4( c_code_str_Context *ctxt, int_fast32_t K, float* A, float* B, float* C ) {\n",
      "EXO_ASSUME(K >= 1);\n",
      "EXO_ASSUME(1 == 1);\n",
      "EXO_ASSUME(1 == 1);\n",
      "EXO_ASSUME(1 == 1);\n",
      "for (int k = 0; k < K; k++) {\n",
      "  for (int i = 0; i < 4; i++) {\n",
      "    for (int j = 0; j < 64; j++) {\n",
      "      C[(i) * (64) + (j) * (1)] += A[(i) * (K) + (k) * (1)] * B[(k) * (64) + (j) * (1)];\n",
      "    }\n",
      "  }\n",
      "}\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###Demonstration of partial_eval() and simplify()\n",
    "for M in range(1, M_REG_BLK+1):\n",
    "    basic_kernel_Mx4[M] = (\n",
    "        SGEMM\n",
    "            .rename(f'basic_kernel_{M}x4')\n",
    "            .partial_eval(M, N_REG_BLK)\n",
    "            .simplify()\n",
    "    )\n",
    "print(basic_kernel_Mx4[4].c_code_str())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "partial_eval(M=N)\n",
    "\n",
    "    replaces the upper bounds identified by M with N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "simplify()\n",
    "\n",
    "    removes all statements that always evalute to true, such as assert(1==1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#include <stdint.h>\n",
      "#include <stdbool.h>\n",
      "\n",
      "// Compiler feature macros adapted from Hedley (public domain)\n",
      "// https://github.com/nemequ/hedley\n",
      "\n",
      "#if defined(__has_builtin)\n",
      "#  define EXO_HAS_BUILTIN(builtin) __has_builtin(builtin)\n",
      "#else\n",
      "#  define EXO_HAS_BUILTIN(builtin) (0)\n",
      "#endif\n",
      "\n",
      "#if EXO_HAS_BUILTIN(__builtin_assume)\n",
      "#  define EXO_ASSUME(expr) __builtin_assume(expr)\n",
      "#elif EXO_HAS_BUILTIN(__builtin_unreachable)\n",
      "#  define EXO_ASSUME(expr) \\\n",
      "      ((void)((expr) ? 1 : (__builtin_unreachable(), 1)))\n",
      "#else\n",
      "#  define EXO_ASSUME(expr) ((void)(expr))\n",
      "#endif\n",
      "\n",
      "typedef struct c_code_str_Context { \n",
      "\n",
      "} c_code_str_Context;\n",
      "\n",
      "\n",
      "// sgemm_kernel_avx512_1x4(\n",
      "//     K : size,\n",
      "//     A : f32[1,K]  @DRAM,\n",
      "//     B : f32[K,64]  @DRAM,\n",
      "//     C : f32[1,64]  @DRAM\n",
      "// )\n",
      "void sgemm_kernel_avx512_1x4( c_code_str_Context *ctxt, int_fast32_t K, float* A, float* B, float* C );\n",
      "\n",
      "\n",
      "static int _floor_div(int num, int quot) {\n",
      "  int off = (num>=0)? 0 : quot-1;\n",
      "  return (num-off)/quot;\n",
      "}\n",
      "\n",
      "static int8_t _clamp_32to8(int32_t x) {\n",
      "  return (x < -128)? -128 : ((x > 127)? 127 : x);\n",
      "}\n",
      "\n",
      "#include <stdio.h>\n",
      "#include <stdlib.h>\n",
      "\n",
      "\n",
      "// sgemm_kernel_avx512_1x4(\n",
      "//     K : size,\n",
      "//     A : f32[1,K]  @DRAM,\n",
      "//     B : f32[K,64]  @DRAM,\n",
      "//     C : f32[1,64]  @DRAM\n",
      "// )\n",
      "void sgemm_kernel_avx512_1x4( c_code_str_Context *ctxt, int_fast32_t K, float* A, float* B, float* C ) {\n",
      "EXO_ASSUME(K >= 1);\n",
      "EXO_ASSUME(1 == 1);\n",
      "EXO_ASSUME(1 == 1);\n",
      "EXO_ASSUME(1 == 1);\n",
      "for (int k = 0; k < K; k++) {\n",
      "  for (int i = 0; i < 1; i++) {\n",
      "    for (int jo = 0; jo < 4; jo++) {\n",
      "      for (int ji = 0; ji < 16; ji++) {\n",
      "        C[(i) * (64) + (16 * jo + ji) * (1)] += A[(i) * (K) + (k) * (1)] * B[(k) * (64) + (16 * jo + ji) * (1)];\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###.split()\n",
    "for M in range(1, M_REG_BLK+1):\n",
    "    sgemm_kernel_avx512_Mx4[M] = (\n",
    "        basic_kernel_Mx4[M]\n",
    "            .rename(f'sgemm_kernel_avx512_{M}x4')\n",
    "            .split('j', VEC_W, ['jo', 'ji'], perfect=True)\n",
    "    )\n",
    "print(sgemm_kernel_avx512_Mx4[1].c_code_str())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".split(loop_var, N, split_loop_names)\n",
    "\n",
    "    splits the loop with variable LOOP_VAR into an outer loop with variable        split_loop_names[0] and a inner loop with variable split_loop_names[1]\n",
    "    The upper bound of the new loops is determined in the following way:\n",
    "\n",
    "    The outer loop upper bound is the upper bound of the original loop / N\n",
    "    The inner loop upper bound is N\n",
    "\n",
    "    This could be very useful when writing blocking procedures, as well as when writing the macrokernels that schedule the calls to the GEMM microkernel "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for M in range(1, M_REG_BLK+1):\n",
    "    sgemm_kernel_avx512_Mx4[M] = (\n",
    "        sgemm_kernel_avx512_Mx4[M]\n",
    "            .par_to_seq('for k in _: _')\n",
    "    )\n",
    "print_output(sgemm_kernel_avx512_Mx4[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "void sgemm_kernel_avx512_1x4( c_code_str_Context *ctxt, int_fast32_t K, float* A, float* B, float* C ) {\n",
      "EXO_ASSUME(K >= 1);\n",
      "EXO_ASSUME(1 == 1);\n",
      "EXO_ASSUME(1 == 1);\n",
      "EXO_ASSUME(1 == 1);\n",
      "for (int k = 0; k < K; k++) {\n",
      "  for (int i = 0; i < 1; i++) {\n",
      "    for (int jo = 0; jo < 4; jo++) {\n",
      "      for (int ji = 0; ji < 16; ji++) {\n",
      "        float C_reg;\n",
      "        C_reg = C[(i) * (64) + (16 * jo + ji) * (1)];\n",
      "        C_reg += A[(i) * (K) + (k) * (1)] * B[(k) * (64) + (16 * jo + ji) * (1)];\n",
      "        C[(i) * (64) + (16 * jo + ji) * (1)] = C_reg;\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for M in range(1, M_REG_BLK+1):\n",
    "    sgemm_kernel_avx512_Mx4[M] = (\n",
    "        basic_kernel_Mx4[M]\n",
    "            .rename(f'sgemm_kernel_avx512_{M}x4')\n",
    "            .split('j', VEC_W, ['jo', 'ji'], perfect=True)\n",
    "            # Mark k as a reduction loop\n",
    "            .par_to_seq('for k in _: _')\n",
    "            # Stage C for reduction\n",
    "            .stage_assn('C_reg', 'C[_] += _')\n",
    "    )\n",
    "print_output(sgemm_kernel_avx512_Mx4[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".stage_assn(var, pattern)\n",
    "\n",
    "    Turns the line that matches PATTERN into the following block of code.\n",
    "    First, create a float named VAR\n",
    "    Second, read the memory originally read by PATTERN into VAR\n",
    "    Third, perform the write operation originally performed in PATTEN on VAR\n",
    "    Finally, write VAR to the memory location read in step 2\n",
    "\n",
    "    Example:\n",
    "    C[i] += A[i]*B[i]\n",
    "    .stage_assn(C_reg, C[_] += _)\n",
    "    C_reg = C[i]\n",
    "    C_reg += A[i]*B[i]\n",
    "    C[i] = C_reg\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "void sgemm_kernel_avx512_1x4( c_code_str_Context *ctxt, int_fast32_t K, float* A, float* B, float* C ) {\n",
      "EXO_ASSUME(K >= 1);\n",
      "EXO_ASSUME(1 == 1);\n",
      "EXO_ASSUME(1 == 1);\n",
      "EXO_ASSUME(1 == 1);\n",
      "float *C_reg = malloc(1 * 4 * 16 * sizeof(*C_reg));\n",
      "for (int k = 0; k < K; k++) {\n",
      "  for (int i = 0; i < 1; i++) {\n",
      "    for (int jo = 0; jo < 4; jo++) {\n",
      "      for (int ji = 0; ji < 16; ji++) {\n",
      "        C_reg[(i) * (4 * 16) + (jo) * (16) + (ji) * (1)] = C[(i) * (64) + (16 * jo + ji) * (1)];\n",
      "        C_reg[(i) * (4 * 16) + (jo) * (16) + (ji) * (1)] += A[(i) * (K) + (k) * (1)] * B[(k) * (64) + (16 * jo + ji) * (1)];\n",
      "        C[(i) * (64) + (16 * jo + ji) * (1)] = C_reg[(i) * (4 * 16) + (jo) * (16) + (ji) * (1)];\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "free(C_reg);\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for M in range(1, M_REG_BLK+1):\n",
    "    sgemm_kernel_avx512_Mx4[M] = (\n",
    "        basic_kernel_Mx4[M]\n",
    "            .rename(f'sgemm_kernel_avx512_{M}x4')\n",
    "            .split('j', VEC_W, ['jo', 'ji'], perfect=True)\n",
    "            # Mark k as a reduction loop\n",
    "            .par_to_seq('for k in _: _')\n",
    "            # Stage C for reduction\n",
    "            .stage_assn('C_reg', 'C[_] += _')\n",
    "            .lift_alloc('C_reg: _', n_lifts=4)\n",
    "    )\n",
    "print_output(sgemm_kernel_avx512_Mx4[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".lift_alloc(pattern, n_lifts)\n",
    "\n",
    "    moves the memory allocation matching PATTERN outside of N_LIFTS for loops\n",
    "    For each loop that PATTERN is lifted out of, the amount of memory allocated to it is multiplied by the upper bound of the loop. This appears to only happen if the upper bound is a static integer, i.e. it won't happen if the upper bound is a variable\n",
    "    Also changes the way in which PATTERN is accessed in its original location. The precise way it does so is a bit confusing, so I think it is easier to think of it in this way:\n",
    "    It lets you load contiguous sections of memory that are as large as the upper bound of the first for loop PATTERN is lifted out of. The number of contiguous sections you load is determined by the upper bounds of the other loops you lift PATTERN out of. This is useful for something like blocking, because you can assign a bunch of contiguous blocks.\n",
    "\n",
    "    Example:\n",
    "    for (int i=0; i<16; ++i) {\n",
    "        float C;\n",
    "        ...\n",
    "    }\n",
    "\n",
    "    .lift_alloc('C: _', n_lifts=1)\n",
    "    \n",
    "    float *C = malloc(sizeof(*C)*16)\n",
    "    for (int i=0; i<16; ++i) {\n",
    "        ...\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " {\n",
      "EXO_ASSUME(K >= 1);\n",
      "EXO_ASSUME(1 == 1);\n",
      "EXO_ASSUME(1 == 1);\n",
      "EXO_ASSUME(1 == 1);\n",
      "float *C_reg = malloc(1 * 4 * 16 * sizeof(*C_reg));\n",
      "for (int i = 0; i < 1; i++) {\n",
      "  for (int jo = 0; jo < 4; jo++) {\n",
      "    for (int ji = 0; ji < 16; ji++) {\n",
      "      C_reg[(i) * (4 * 16) + (jo) * (16) + (ji) * (1)] = C[(i) * (64) + (16 * jo + ji) * (1)];\n",
      "    }\n",
      "  }\n",
      "}\n",
      "for (int k = 0; k < K; k++) {\n",
      "  for (int i = 0; i < 1; i++) {\n",
      "    for (int jo = 0; jo < 4; jo++) {\n",
      "      for (int ji = 0; ji < 16; ji++) {\n",
      "        C_reg[(i) * (4 * 16) + (jo) * (16) + (ji) * (1)] += A[(i) * (K) + (k) * (1)] * B[(k) * (64) + (16 * jo + ji) * (1)];\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "for (int i = 0; i < 1; i++) {\n",
      "  for (int jo = 0; jo < 4; jo++) {\n",
      "    for (int ji = 0; ji < 16; ji++) {\n",
      "      C[(i) * (64) + (16 * jo + ji) * (1)] = C_reg[(i) * (4 * 16) + (jo) * (16) + (ji) * (1)];\n",
      "    }\n",
      "  }\n",
      "}\n",
      "free(C_reg);\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for M in range(1, M_REG_BLK+1):\n",
    "    sgemm_kernel_avx512_Mx4[M] = (\n",
    "        basic_kernel_Mx4[M]\n",
    "            .rename(f'sgemm_kernel_avx512_{M}x4')\n",
    "            .split('j', VEC_W, ['jo', 'ji'], perfect=True)\n",
    "            # Mark k as a reduction loop\n",
    "            .par_to_seq('for k in _: _')\n",
    "            # Stage C for reduction\n",
    "            .stage_assn('C_reg', 'C[_] += _')\n",
    "            .lift_alloc('C_reg: _', n_lifts=4)\n",
    "            .double_fission('C_reg[_] = C[_]', 'C_reg[_] += _', n_lifts=4)\n",
    "    )\n",
    "print_output(sgemm_kernel_avx512_Mx4[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".double_fission(pattern1, pattern2, n_lifts)\n",
    "\n",
    "    Lift PATTERN1 n_lifts loops above its current location and also copies the n_lifts-1 loops above PATTERN, wrapping pattern in those loops.\n",
    "\n",
    "    Does the same thing to PATTERN2, but it moves it below its original location instead of above. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#include <stdint.h>\n",
      "#include <stdbool.h>\n",
      "\n",
      "// Compiler feature macros adapted from Hedley (public domain)\n",
      "// https://github.com/nemequ/hedley\n",
      "\n",
      "#if defined(__has_builtin)\n",
      "#  define EXO_HAS_BUILTIN(builtin) __has_builtin(builtin)\n",
      "#else\n",
      "#  define EXO_HAS_BUILTIN(builtin) (0)\n",
      "#endif\n",
      "\n",
      "#if EXO_HAS_BUILTIN(__builtin_assume)\n",
      "#  define EXO_ASSUME(expr) __builtin_assume(expr)\n",
      "#elif EXO_HAS_BUILTIN(__builtin_unreachable)\n",
      "#  define EXO_ASSUME(expr) \\\n",
      "      ((void)((expr) ? 1 : (__builtin_unreachable(), 1)))\n",
      "#else\n",
      "#  define EXO_ASSUME(expr) ((void)(expr))\n",
      "#endif\n",
      "\n",
      "typedef struct c_code_str_Context { \n",
      "\n",
      "} c_code_str_Context;\n",
      "\n",
      "\n",
      "// sgemm_kernel_avx512_1x4(\n",
      "//     K : size,\n",
      "//     A : f32[1,K]  @DRAM,\n",
      "//     B : f32[K,64]  @DRAM,\n",
      "//     C : f32[1,64]  @DRAM\n",
      "// )\n",
      "void sgemm_kernel_avx512_1x4( c_code_str_Context *ctxt, int_fast32_t K, float* A, float* B, float* C );\n",
      "\n",
      "\n",
      "static int _floor_div(int num, int quot) {\n",
      "  int off = (num>=0)? 0 : quot-1;\n",
      "  return (num-off)/quot;\n",
      "}\n",
      "\n",
      "static int8_t _clamp_32to8(int32_t x) {\n",
      "  return (x < -128)? -128 : ((x > 127)? 127 : x);\n",
      "}\n",
      "\n",
      "#include <stdio.h>\n",
      "#include <stdlib.h>\n",
      "\n",
      "\n",
      "#include <stdio.h>\n",
      "#include <stdlib.h>\n",
      "\n",
      "\n",
      "// sgemm_kernel_avx512_1x4(\n",
      "//     K : size,\n",
      "//     A : f32[1,K]  @DRAM,\n",
      "//     B : f32[K,64]  @DRAM,\n",
      "//     C : f32[1,64]  @DRAM\n",
      "// )\n",
      "void sgemm_kernel_avx512_1x4( c_code_str_Context *ctxt, int_fast32_t K, float* A, float* B, float* C ) {\n",
      "EXO_ASSUME(K >= 1);\n",
      "EXO_ASSUME(1 == 1);\n",
      "EXO_ASSUME(1 == 1);\n",
      "EXO_ASSUME(1 == 1);\n",
      "static float C_reg[1 * 4 * 16];\n",
      "for (int i = 0; i < 1; i++) {\n",
      "  for (int jo = 0; jo < 4; jo++) {\n",
      "    for (int ji = 0; ji < 16; ji++) {\n",
      "      C_reg[(i) * (4 * 16) + (jo) * (16) + (ji) * (1)] = C[(i) * (64) + (16 * jo + ji) * (1)];\n",
      "    }\n",
      "  }\n",
      "}\n",
      "for (int k = 0; k < K; k++) {\n",
      "  for (int i = 0; i < 1; i++) {\n",
      "    for (int jo = 0; jo < 4; jo++) {\n",
      "      static float A_vec[16];\n",
      "      for (int ji = 0; ji < 16; ji++) {\n",
      "        A_vec[(ji) * (1)] = A[(i) * (K) + (k) * (1)];\n",
      "      }\n",
      "      static float B_vec[16];\n",
      "      for (int ji = 0; ji < 16; ji++) {\n",
      "        B_vec[(ji) * (1)] = B[(k) * (64) + (16 * jo + ji) * (1)];\n",
      "      }\n",
      "      for (int ji = 0; ji < 16; ji++) {\n",
      "        C_reg[(i) * (4 * 16) + (jo) * (16) + (ji) * (1)] += A_vec[(ji) * (1)] * B_vec[(ji) * (1)];\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "for (int i = 0; i < 1; i++) {\n",
      "  for (int jo = 0; jo < 4; jo++) {\n",
      "    for (int ji = 0; ji < 16; ji++) {\n",
      "      C[(i) * (64) + (16 * jo + ji) * (1)] = C_reg[(i) * (4 * 16) + (jo) * (16) + (ji) * (1)];\n",
      "    }\n",
      "  }\n",
      "}\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for M in range(1, M_REG_BLK+1):\n",
    "    sgemm_kernel_avx512_Mx4[M] = (\n",
    "        basic_kernel_Mx4[M]\n",
    "            .rename(f'sgemm_kernel_avx512_{M}x4')\n",
    "            .split('j', VEC_W, ['jo', 'ji'], perfect=True)\n",
    "            # Mark k as a reduction loop\n",
    "            .par_to_seq('for k in _: _')\n",
    "            # Stage C for reduction\n",
    "            .stage_assn('C_reg', 'C[_] += _')\n",
    "            .set_memory('C_reg', DRAM_STATIC)\n",
    "            .lift_alloc('C_reg: _', n_lifts=4)\n",
    "            .double_fission('C_reg[_] = C[_]', 'C_reg[_] += _', n_lifts=4)\n",
    "            .stage_expr('A_vec', 'A[_, _]', memory=DRAM_STATIC)\n",
    "            .stage_expr('B_vec', 'B[_, _]', memory=DRAM_STATIC)\n",
    "    )\n",
    "print(sgemm_kernel_avx512_Mx4[1].c_code_str())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "replace_all(expr)\n",
    "\n",
    "    No idea how it picks what to replace, but my best guess is that it just picks the original loop and replaces it with the expression\n",
    "\n",
    "replace(expr, pattern)\n",
    "\n",
    "    Replaces the pattern with the expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "void sgemm_kernel_avx512_1x4( c_code_str_Context *ctxt, int_fast32_t K, float* A, float* B, float* C )\n",
      " {\n",
      "EXO_ASSUME(K >= 1);\n",
      "EXO_ASSUME(1 == 1);\n",
      "EXO_ASSUME(1 == 1);\n",
      "EXO_ASSUME(1 == 1);\n",
      "__m512 C_reg[1][4];\n",
      "for (int i = 0; i < 1; i++) {\n",
      "  for (int jo = 0; jo < 4; jo++) {\n",
      "    C_reg[i][jo] = _mm512_loadu_ps(&C[(i) * (64) + (16 * jo) * (1)]);\n",
      "  }\n",
      "}\n",
      "for (int k = 0; k < K; k++) {\n",
      "  for (int i = 0; i < 1; i++) {\n",
      "    __m512 A_vec;\n",
      "    (A_vec) = _mm512_set1_ps(A[(i) * (K) + (k) * (1)]);\n",
      "    for (int jo = 0; jo < 4; jo++) {\n",
      "      __m512 B_vec;\n",
      "      B_vec = _mm512_loadu_ps(&B[(k) * (64) + (16 * jo) * (1)]);\n",
      "      C_reg[i][jo] = _mm512_fmadd_ps((A_vec), (B_vec), C_reg[i][jo]);\n",
      "    }\n",
      "  }\n",
      "}\n",
      "for (int i = 0; i < 1; i++) {\n",
      "  for (int jo = 0; jo < 4; jo++) {\n",
      "    _mm512_storeu_ps(&C[(i) * (64) + (16 * jo) * (1)], C_reg[i][jo]);\n",
      "  }\n",
      "}\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Make each of the microkernels. Each one multiplies a a M_r*K_c strip of A with a K_c*N_r strip of B.\n",
    "#Appears to mirror the style of Goto and van der Geijn\n",
    "for M in range(1, M_REG_BLK+1):\n",
    "    sgemm_kernel_avx512_Mx4[M] = (\n",
    "        basic_kernel_Mx4[M]\n",
    "            .rename(f'sgemm_kernel_avx512_{M}x4')\n",
    "            .split('j', VEC_W, ['jo', 'ji'], perfect=True)\n",
    "            # Mark k as a reduction loop\n",
    "            .par_to_seq('for k in _: _')\n",
    "            # Stage C for reduction\n",
    "            .stage_assn('C_reg', 'C[_] += _')\n",
    "            .set_memory('C_reg', AVX512)\n",
    "            .lift_alloc('C_reg: _', n_lifts=4)\n",
    "            .double_fission('C_reg[_] = C[_]', 'C_reg[_] += _', n_lifts=4)\n",
    "            .stage_expr('A_vec', 'A[_, _]', memory=AVX512)\n",
    "            .stage_expr('B_vec', 'B[_, _]', memory=AVX512)\n",
    "            # Schedule ops\n",
    "            .replace(mm512_loadu_ps, 'for ji in _: _ #0')\n",
    "            .replace(mm512_storeu_ps, 'for ji in _: _ #3')\n",
    "            .replace_all(mm512_set1_ps)\n",
    "            .replace_all(mm512_loadu_ps)\n",
    "            .replace_all(mm512_fmadd_ps)\n",
    "            # LICM\n",
    "            .lift_alloc('A_vec: _')\n",
    "            .fission_after('mm512_set1_ps(_)')\n",
    "            # Clean up\n",
    "            .simplify()\n",
    "    )\n",
    "print_output(sgemm_kernel_avx512_Mx4[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lift_alloc(pattern)\n",
    "\n",
    "    moves the memory allocation statement matching PATTERN one loop higher\n",
    "\n",
    "fission_after(pattern)\n",
    "\n",
    "    moves the generic statement matching PATTERN one loop higher and matches it with an allocation statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#include <stdint.h>\n",
      "#include <stdbool.h>\n",
      "\n",
      "// Compiler feature macros adapted from Hedley (public domain)\n",
      "// https://github.com/nemequ/hedley\n",
      "\n",
      "#if defined(__has_builtin)\n",
      "#  define EXO_HAS_BUILTIN(builtin) __has_builtin(builtin)\n",
      "#else\n",
      "#  define EXO_HAS_BUILTIN(builtin) (0)\n",
      "#endif\n",
      "\n",
      "#if EXO_HAS_BUILTIN(__builtin_assume)\n",
      "#  define EXO_ASSUME(expr) __builtin_assume(expr)\n",
      "#elif EXO_HAS_BUILTIN(__builtin_unreachable)\n",
      "#  define EXO_ASSUME(expr) \\\n",
      "      ((void)((expr) ? 1 : (__builtin_unreachable(), 1)))\n",
      "#else\n",
      "#  define EXO_ASSUME(expr) ((void)(expr))\n",
      "#endif\n",
      "\n",
      "typedef struct c_code_str_Context { \n",
      "\n",
      "} c_code_str_Context;\n",
      "\n",
      "\n",
      "// bottom_panel_kernel(\n",
      "//     M : size,\n",
      "//     K : size,\n",
      "//     A : f32[M,K]  @DRAM,\n",
      "//     B : f32[K,64]  @DRAM,\n",
      "//     C : f32[M,64]  @DRAM\n",
      "// )\n",
      "void bottom_panel_kernel( c_code_str_Context *ctxt, int_fast32_t M, int_fast32_t K, float* A, float* B, float* C );\n",
      "\n",
      "\n",
      "static int _floor_div(int num, int quot) {\n",
      "  int off = (num>=0)? 0 : quot-1;\n",
      "  return (num-off)/quot;\n",
      "}\n",
      "\n",
      "static int8_t _clamp_32to8(int32_t x) {\n",
      "  return (x < -128)? -128 : ((x > 127)? 127 : x);\n",
      "}\n",
      "\n",
      "#include <stdio.h>\n",
      "#include <stdlib.h>\n",
      "\n",
      "\n",
      "// bottom_panel_kernel(\n",
      "//     M : size,\n",
      "//     K : size,\n",
      "//     A : f32[M,K]  @DRAM,\n",
      "//     B : f32[K,64]  @DRAM,\n",
      "//     C : f32[M,64]  @DRAM\n",
      "// )\n",
      "void bottom_panel_kernel( c_code_str_Context *ctxt, int_fast32_t M, int_fast32_t K, float* A, float* B, float* C ) {\n",
      "EXO_ASSUME(M >= 1);\n",
      "EXO_ASSUME(K >= 1);\n",
      "EXO_ASSUME(1 == 1);\n",
      "EXO_ASSUME(1 == 1);\n",
      "EXO_ASSUME(1 == 1);\n",
      "EXO_ASSUME(M < 6);\n",
      "for (int k = 0; k < K; k++) {\n",
      "  for (int i = 0; i < M; i++) {\n",
      "    for (int j = 0; j < 64; j++) {\n",
      "      C[(i) * (64) + (j) * (1)] += A[(i) * (K) + (k) * (1)] * B[(k) * (64) + (j) * (1)];\n",
      "    }\n",
      "  }\n",
      "}\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This stuff multiplies a M_r*K_c panel of A by a N_r*K_c panel of B\n",
    "# When the microkernel stuff is added in the cell below this one, it calls the appropriate microkernel\n",
    "# to multiply the M_r*K_c strip of A by the K_c*N_r strip of B. So it's like a long, thin horizontal panel of A \n",
    "# multiplied by a long, vertical panel of B\n",
    "bottom_panel_kernel = (\n",
    "    SGEMM\n",
    "        .rename('bottom_panel_kernel')\n",
    "        .partial_eval(N=N_REG_BLK)\n",
    "        .add_assertion(f'M < {M_REG_BLK}')\n",
    "        .simplify()\n",
    ")\n",
    "print(bottom_panel_kernel.c_code_str())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#include <stdint.h>\n",
      "#include <stdbool.h>\n",
      "\n",
      "// Compiler feature macros adapted from Hedley (public domain)\n",
      "// https://github.com/nemequ/hedley\n",
      "\n",
      "#if defined(__has_builtin)\n",
      "#  define EXO_HAS_BUILTIN(builtin) __has_builtin(builtin)\n",
      "#else\n",
      "#  define EXO_HAS_BUILTIN(builtin) (0)\n",
      "#endif\n",
      "\n",
      "#if EXO_HAS_BUILTIN(__builtin_assume)\n",
      "#  define EXO_ASSUME(expr) __builtin_assume(expr)\n",
      "#elif EXO_HAS_BUILTIN(__builtin_unreachable)\n",
      "#  define EXO_ASSUME(expr) \\\n",
      "      ((void)((expr) ? 1 : (__builtin_unreachable(), 1)))\n",
      "#else\n",
      "#  define EXO_ASSUME(expr) ((void)(expr))\n",
      "#endif\n",
      "\n",
      "struct exo_win_2f32{\n",
      "    float *data;\n",
      "    int_fast32_t strides[2];\n",
      "};\n",
      "struct exo_win_1f32{\n",
      "    float *data;\n",
      "    int_fast32_t strides[1];\n",
      "};\n",
      "typedef struct c_code_str_Context { \n",
      "\n",
      "} c_code_str_Context;\n",
      "\n",
      "\n",
      "// bottom_panel_kernel_scheduled(\n",
      "//     M : size,\n",
      "//     K : size,\n",
      "//     A : [f32][M,K]  @DRAM,\n",
      "//     B : [f32][K,64]  @DRAM,\n",
      "//     C : [f32][M,64]  @DRAM\n",
      "// )\n",
      "void bottom_panel_kernel_scheduled( c_code_str_Context *ctxt, int_fast32_t M, int_fast32_t K, struct exo_win_2f32 A, struct exo_win_2f32 B, struct exo_win_2f32 C );\n",
      "\n",
      "\n",
      "static int _floor_div(int num, int quot) {\n",
      "  int off = (num>=0)? 0 : quot-1;\n",
      "  return (num-off)/quot;\n",
      "}\n",
      "\n",
      "static int8_t _clamp_32to8(int32_t x) {\n",
      "  return (x < -128)? -128 : ((x > 127)? 127 : x);\n",
      "}\n",
      "\n",
      "#include <immintrin.h>\n",
      "\n",
      "#include <stdio.h>\n",
      "#include <stdlib.h>\n",
      "\n",
      "\n",
      "// sgemm_kernel_avx512_4x4(\n",
      "//     K : size,\n",
      "//     A : [f32][4,K]  @DRAM,\n",
      "//     B : [f32][K,64]  @DRAM,\n",
      "//     C : [f32][4,64]  @DRAM\n",
      "// )\n",
      "void sgemm_kernel_avx512_4x4( c_code_str_Context *ctxt, int_fast32_t K, struct exo_win_2f32 A, struct exo_win_2f32 B, struct exo_win_2f32 C ) {\n",
      "EXO_ASSUME(K >= 1);\n",
      "EXO_ASSUME(A.strides[1] == 1);\n",
      "EXO_ASSUME(B.strides[1] == 1);\n",
      "EXO_ASSUME(C.strides[1] == 1);\n",
      "__m512 C_reg[4][4];\n",
      "for (int i = 0; i < 4; i++) {\n",
      "  for (int jo = 0; jo < 4; jo++) {\n",
      "    C_reg[i][jo] = _mm512_loadu_ps(&C.data[(i) * (C.strides[0]) + (16 * jo) * (C.strides[1])]);\n",
      "  }\n",
      "}\n",
      "for (int k = 0; k < K; k++) {\n",
      "  for (int i = 0; i < 4; i++) {\n",
      "    __m512 A_vec;\n",
      "    (A_vec) = _mm512_set1_ps(A.data[(i) * (A.strides[0]) + (k) * (A.strides[1])]);\n",
      "    for (int jo = 0; jo < 4; jo++) {\n",
      "      __m512 B_vec;\n",
      "      B_vec = _mm512_loadu_ps(&B.data[(k) * (B.strides[0]) + (16 * jo) * (B.strides[1])]);\n",
      "      C_reg[i][jo] = _mm512_fmadd_ps((A_vec), (B_vec), C_reg[i][jo]);\n",
      "    }\n",
      "  }\n",
      "}\n",
      "for (int i = 0; i < 4; i++) {\n",
      "  for (int jo = 0; jo < 4; jo++) {\n",
      "    _mm512_storeu_ps(&C.data[(i) * (C.strides[0]) + (16 * jo) * (C.strides[1])], C_reg[i][jo]);\n",
      "  }\n",
      "}\n",
      "}\n",
      "\n",
      "// sgemm_kernel_avx512_3x4(\n",
      "//     K : size,\n",
      "//     A : [f32][3,K]  @DRAM,\n",
      "//     B : [f32][K,64]  @DRAM,\n",
      "//     C : [f32][3,64]  @DRAM\n",
      "// )\n",
      "void sgemm_kernel_avx512_3x4( c_code_str_Context *ctxt, int_fast32_t K, struct exo_win_2f32 A, struct exo_win_2f32 B, struct exo_win_2f32 C ) {\n",
      "EXO_ASSUME(K >= 1);\n",
      "EXO_ASSUME(A.strides[1] == 1);\n",
      "EXO_ASSUME(B.strides[1] == 1);\n",
      "EXO_ASSUME(C.strides[1] == 1);\n",
      "__m512 C_reg[3][4];\n",
      "for (int i = 0; i < 3; i++) {\n",
      "  for (int jo = 0; jo < 4; jo++) {\n",
      "    C_reg[i][jo] = _mm512_loadu_ps(&C.data[(i) * (C.strides[0]) + (16 * jo) * (C.strides[1])]);\n",
      "  }\n",
      "}\n",
      "for (int k = 0; k < K; k++) {\n",
      "  for (int i = 0; i < 3; i++) {\n",
      "    __m512 A_vec;\n",
      "    (A_vec) = _mm512_set1_ps(A.data[(i) * (A.strides[0]) + (k) * (A.strides[1])]);\n",
      "    for (int jo = 0; jo < 4; jo++) {\n",
      "      __m512 B_vec;\n",
      "      B_vec = _mm512_loadu_ps(&B.data[(k) * (B.strides[0]) + (16 * jo) * (B.strides[1])]);\n",
      "      C_reg[i][jo] = _mm512_fmadd_ps((A_vec), (B_vec), C_reg[i][jo]);\n",
      "    }\n",
      "  }\n",
      "}\n",
      "for (int i = 0; i < 3; i++) {\n",
      "  for (int jo = 0; jo < 4; jo++) {\n",
      "    _mm512_storeu_ps(&C.data[(i) * (C.strides[0]) + (16 * jo) * (C.strides[1])], C_reg[i][jo]);\n",
      "  }\n",
      "}\n",
      "}\n",
      "\n",
      "// sgemm_kernel_avx512_1x4(\n",
      "//     K : size,\n",
      "//     A : [f32][1,K]  @DRAM,\n",
      "//     B : [f32][K,64]  @DRAM,\n",
      "//     C : [f32][1,64]  @DRAM\n",
      "// )\n",
      "void sgemm_kernel_avx512_1x4( c_code_str_Context *ctxt, int_fast32_t K, struct exo_win_2f32 A, struct exo_win_2f32 B, struct exo_win_2f32 C ) {\n",
      "EXO_ASSUME(K >= 1);\n",
      "EXO_ASSUME(A.strides[1] == 1);\n",
      "EXO_ASSUME(B.strides[1] == 1);\n",
      "EXO_ASSUME(C.strides[1] == 1);\n",
      "__m512 C_reg[1][4];\n",
      "for (int i = 0; i < 1; i++) {\n",
      "  for (int jo = 0; jo < 4; jo++) {\n",
      "    C_reg[i][jo] = _mm512_loadu_ps(&C.data[(i) * (C.strides[0]) + (16 * jo) * (C.strides[1])]);\n",
      "  }\n",
      "}\n",
      "for (int k = 0; k < K; k++) {\n",
      "  for (int i = 0; i < 1; i++) {\n",
      "    __m512 A_vec;\n",
      "    (A_vec) = _mm512_set1_ps(A.data[(i) * (A.strides[0]) + (k) * (A.strides[1])]);\n",
      "    for (int jo = 0; jo < 4; jo++) {\n",
      "      __m512 B_vec;\n",
      "      B_vec = _mm512_loadu_ps(&B.data[(k) * (B.strides[0]) + (16 * jo) * (B.strides[1])]);\n",
      "      C_reg[i][jo] = _mm512_fmadd_ps((A_vec), (B_vec), C_reg[i][jo]);\n",
      "    }\n",
      "  }\n",
      "}\n",
      "for (int i = 0; i < 1; i++) {\n",
      "  for (int jo = 0; jo < 4; jo++) {\n",
      "    _mm512_storeu_ps(&C.data[(i) * (C.strides[0]) + (16 * jo) * (C.strides[1])], C_reg[i][jo]);\n",
      "  }\n",
      "}\n",
      "}\n",
      "\n",
      "// sgemm_kernel_avx512_2x4(\n",
      "//     K : size,\n",
      "//     A : [f32][2,K]  @DRAM,\n",
      "//     B : [f32][K,64]  @DRAM,\n",
      "//     C : [f32][2,64]  @DRAM\n",
      "// )\n",
      "void sgemm_kernel_avx512_2x4( c_code_str_Context *ctxt, int_fast32_t K, struct exo_win_2f32 A, struct exo_win_2f32 B, struct exo_win_2f32 C ) {\n",
      "EXO_ASSUME(K >= 1);\n",
      "EXO_ASSUME(A.strides[1] == 1);\n",
      "EXO_ASSUME(B.strides[1] == 1);\n",
      "EXO_ASSUME(C.strides[1] == 1);\n",
      "__m512 C_reg[2][4];\n",
      "for (int i = 0; i < 2; i++) {\n",
      "  for (int jo = 0; jo < 4; jo++) {\n",
      "    C_reg[i][jo] = _mm512_loadu_ps(&C.data[(i) * (C.strides[0]) + (16 * jo) * (C.strides[1])]);\n",
      "  }\n",
      "}\n",
      "for (int k = 0; k < K; k++) {\n",
      "  for (int i = 0; i < 2; i++) {\n",
      "    __m512 A_vec;\n",
      "    (A_vec) = _mm512_set1_ps(A.data[(i) * (A.strides[0]) + (k) * (A.strides[1])]);\n",
      "    for (int jo = 0; jo < 4; jo++) {\n",
      "      __m512 B_vec;\n",
      "      B_vec = _mm512_loadu_ps(&B.data[(k) * (B.strides[0]) + (16 * jo) * (B.strides[1])]);\n",
      "      C_reg[i][jo] = _mm512_fmadd_ps((A_vec), (B_vec), C_reg[i][jo]);\n",
      "    }\n",
      "  }\n",
      "}\n",
      "for (int i = 0; i < 2; i++) {\n",
      "  for (int jo = 0; jo < 4; jo++) {\n",
      "    _mm512_storeu_ps(&C.data[(i) * (C.strides[0]) + (16 * jo) * (C.strides[1])], C_reg[i][jo]);\n",
      "  }\n",
      "}\n",
      "}\n",
      "\n",
      "\n",
      "/* relying on the following instruction...\n",
      "mm512_storeu_ps(dst,src)\n",
      "_mm512_storeu_ps(&{dst_data}, {src_data});\n",
      "*/\n",
      "\n",
      "\n",
      "/* relying on the following instruction...\n",
      "mm512_set1_ps(dst,src)\n",
      "{dst} = _mm512_set1_ps({src_data});\n",
      "*/\n",
      "\n",
      "\n",
      "/* relying on the following instruction...\n",
      "mm512_fmadd_ps(A,B,C)\n",
      "{C_data} = _mm512_fmadd_ps({A}, {B}, {C_data});\n",
      "*/\n",
      "\n",
      "\n",
      "/* relying on the following instruction...\n",
      "mm512_loadu_ps(dst,src)\n",
      "{dst_data} = _mm512_loadu_ps(&{src_data});\n",
      "*/\n",
      "\n",
      "// sgemm_kernel_avx512_5x4(\n",
      "//     K : size,\n",
      "//     A : [f32][5,K]  @DRAM,\n",
      "//     B : [f32][K,64]  @DRAM,\n",
      "//     C : [f32][5,64]  @DRAM\n",
      "// )\n",
      "void sgemm_kernel_avx512_5x4( c_code_str_Context *ctxt, int_fast32_t K, struct exo_win_2f32 A, struct exo_win_2f32 B, struct exo_win_2f32 C ) {\n",
      "EXO_ASSUME(K >= 1);\n",
      "EXO_ASSUME(A.strides[1] == 1);\n",
      "EXO_ASSUME(B.strides[1] == 1);\n",
      "EXO_ASSUME(C.strides[1] == 1);\n",
      "__m512 C_reg[5][4];\n",
      "for (int i = 0; i < 5; i++) {\n",
      "  for (int jo = 0; jo < 4; jo++) {\n",
      "    C_reg[i][jo] = _mm512_loadu_ps(&C.data[(i) * (C.strides[0]) + (16 * jo) * (C.strides[1])]);\n",
      "  }\n",
      "}\n",
      "for (int k = 0; k < K; k++) {\n",
      "  for (int i = 0; i < 5; i++) {\n",
      "    __m512 A_vec;\n",
      "    (A_vec) = _mm512_set1_ps(A.data[(i) * (A.strides[0]) + (k) * (A.strides[1])]);\n",
      "    for (int jo = 0; jo < 4; jo++) {\n",
      "      __m512 B_vec;\n",
      "      B_vec = _mm512_loadu_ps(&B.data[(k) * (B.strides[0]) + (16 * jo) * (B.strides[1])]);\n",
      "      C_reg[i][jo] = _mm512_fmadd_ps((A_vec), (B_vec), C_reg[i][jo]);\n",
      "    }\n",
      "  }\n",
      "}\n",
      "for (int i = 0; i < 5; i++) {\n",
      "  for (int jo = 0; jo < 4; jo++) {\n",
      "    _mm512_storeu_ps(&C.data[(i) * (C.strides[0]) + (16 * jo) * (C.strides[1])], C_reg[i][jo]);\n",
      "  }\n",
      "}\n",
      "}\n",
      "\n",
      "// bottom_panel_kernel_scheduled(\n",
      "//     M : size,\n",
      "//     K : size,\n",
      "//     A : [f32][M,K]  @DRAM,\n",
      "//     B : [f32][K,64]  @DRAM,\n",
      "//     C : [f32][M,64]  @DRAM\n",
      "// )\n",
      "void bottom_panel_kernel_scheduled( c_code_str_Context *ctxt, int_fast32_t M, int_fast32_t K, struct exo_win_2f32 A, struct exo_win_2f32 B, struct exo_win_2f32 C ) {\n",
      "EXO_ASSUME(M >= 1);\n",
      "EXO_ASSUME(K >= 1);\n",
      "EXO_ASSUME(A.strides[1] == 1);\n",
      "EXO_ASSUME(B.strides[1] == 1);\n",
      "EXO_ASSUME(C.strides[1] == 1);\n",
      "EXO_ASSUME(M < 6);\n",
      "if (M == 1) {\n",
      "  sgemm_kernel_avx512_1x4(ctxt,K,(struct exo_win_2f32){ (float*)&A.data[(0) * (A.strides[0]) + (0) * (A.strides[1])], { A.strides[0], A.strides[1] } },(struct exo_win_2f32){ (float*)&B.data[(0) * (B.strides[0]) + (0) * (B.strides[1])], { B.strides[0], B.strides[1] } },(struct exo_win_2f32){ (float*)&C.data[(0) * (C.strides[0]) + (0) * (C.strides[1])], { C.strides[0], C.strides[1] } });\n",
      "} else {\n",
      "  if (M == 2) {\n",
      "    sgemm_kernel_avx512_2x4(ctxt,K,(struct exo_win_2f32){ (float*)&A.data[(0) * (A.strides[0]) + (0) * (A.strides[1])], { A.strides[0], A.strides[1] } },(struct exo_win_2f32){ (float*)&B.data[(0) * (B.strides[0]) + (0) * (B.strides[1])], { B.strides[0], B.strides[1] } },(struct exo_win_2f32){ (float*)&C.data[(0) * (C.strides[0]) + (0) * (C.strides[1])], { C.strides[0], C.strides[1] } });\n",
      "  } else {\n",
      "    if (M == 3) {\n",
      "      sgemm_kernel_avx512_3x4(ctxt,K,(struct exo_win_2f32){ (float*)&A.data[(0) * (A.strides[0]) + (0) * (A.strides[1])], { A.strides[0], A.strides[1] } },(struct exo_win_2f32){ (float*)&B.data[(0) * (B.strides[0]) + (0) * (B.strides[1])], { B.strides[0], B.strides[1] } },(struct exo_win_2f32){ (float*)&C.data[(0) * (C.strides[0]) + (0) * (C.strides[1])], { C.strides[0], C.strides[1] } });\n",
      "    } else {\n",
      "      if (M == 4) {\n",
      "        sgemm_kernel_avx512_4x4(ctxt,K,(struct exo_win_2f32){ (float*)&A.data[(0) * (A.strides[0]) + (0) * (A.strides[1])], { A.strides[0], A.strides[1] } },(struct exo_win_2f32){ (float*)&B.data[(0) * (B.strides[0]) + (0) * (B.strides[1])], { B.strides[0], B.strides[1] } },(struct exo_win_2f32){ (float*)&C.data[(0) * (C.strides[0]) + (0) * (C.strides[1])], { C.strides[0], C.strides[1] } });\n",
      "      } else {\n",
      "        if (M == 5) {\n",
      "          sgemm_kernel_avx512_5x4(ctxt,K,(struct exo_win_2f32){ (float*)&A.data[(0) * (A.strides[0]) + (0) * (A.strides[1])], { A.strides[0], A.strides[1] } },(struct exo_win_2f32){ (float*)&B.data[(0) * (B.strides[0]) + (0) * (B.strides[1])], { B.strides[0], B.strides[1] } },(struct exo_win_2f32){ (float*)&C.data[(0) * (C.strides[0]) + (0) * (C.strides[1])], { C.strides[0], C.strides[1] } });\n",
      "        } else {\n",
      "          for (int k = 0; k < K; k++) {\n",
      "            for (int i = 0; i < M; i++) {\n",
      "              for (int j = 0; j < 64; j++) {\n",
      "                C.data[(i) * (C.strides[0]) + (j) * (C.strides[1])] += A.data[(i) * (A.strides[0]) + (k) * (A.strides[1])] * B.data[(k) * (B.strides[0]) + (j) * (B.strides[1])];\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SGEMM_WINDOW = (SGEMM.rename('SGEMM_WINDOW')\n",
    "                .set_window('A', True)\n",
    "                .set_window('B', True)\n",
    "                .set_window('C', True))\n",
    "\n",
    "# Constants for scheduling\n",
    "VEC_W = 16\n",
    "\n",
    "M_REG_BLK = 6\n",
    "N_REG_BLK = (4 * VEC_W)\n",
    "\n",
    "M_L1_FAC = 44\n",
    "N_L1_FAC = 1\n",
    "\n",
    "M_L1_BLK = M_REG_BLK * M_L1_FAC\n",
    "N_L1_BLK = N_REG_BLK * N_L1_FAC\n",
    "K_L1_BLK = 512\n",
    "\n",
    "basic_kernel_Mx4 = {}\n",
    "sgemm_kernel_avx512_Mx4 = {}\n",
    "for M in range(1, M_REG_BLK + 1):\n",
    "    basic_kernel_Mx4[M] = (\n",
    "        SGEMM_WINDOW\n",
    "            .rename(f'basic_kernel_{M}x4')\n",
    "            .partial_eval(M, N_REG_BLK)\n",
    "            .simplify()\n",
    "    )\n",
    "    sgemm_kernel_avx512_Mx4[M] = (\n",
    "        basic_kernel_Mx4[M]\n",
    "            .rename(f'sgemm_kernel_avx512_{M}x4')\n",
    "            # Vectorize columns\n",
    "            .split('j', VEC_W, ['jo', 'ji'], perfect=True)\n",
    "            # Mark k as a reduction loop\n",
    "            .par_to_seq('for k in _: _')\n",
    "            # Stage C for reduction\n",
    "            .stage_assn('C_reg', 'C[_] += _')\n",
    "            .set_memory('C_reg', AVX512)\n",
    "            .lift_alloc('C_reg: _', n_lifts=4)\n",
    "            .double_fission('C_reg[_] = C[_]', 'C_reg[_] += _', n_lifts=4)\n",
    "            # Stage A & B\n",
    "            .stage_expr('A_vec', 'A[_, _]', memory=AVX512)\n",
    "            .stage_expr('B_vec', 'B[_, _]', memory=AVX512)\n",
    "            # Schedule ops\n",
    "            .replace(mm512_loadu_ps, 'for ji in _: _ #0')\n",
    "            .replace(mm512_storeu_ps, 'for ji in _: _ #3')\n",
    "            .replace_all(mm512_set1_ps)\n",
    "            .replace_all(mm512_loadu_ps)\n",
    "            .replace_all(mm512_fmadd_ps)\n",
    "            # LICM\n",
    "            .lift_alloc('A_vec: _')\n",
    "            .fission_after('mm512_set1_ps(_)')\n",
    "            # Clean up\n",
    "            .simplify()\n",
    "    )\n",
    "\n",
    "bottom_panel_kernel = (\n",
    "    SGEMM_WINDOW\n",
    "        .rename('bottom_panel_kernel')\n",
    "        .partial_eval(N=N_REG_BLK)\n",
    "        .add_assertion(f'M < {M_REG_BLK}')\n",
    "        .simplify()\n",
    ")\n",
    "\n",
    "bottom_panel_kernel_scheduled = (\n",
    "    bottom_panel_kernel\n",
    "        .rename('bottom_panel_kernel_scheduled')\n",
    "        # Specialize branches (simplify needed to unify with basic kernels)\n",
    "        .specialize('for k in _: _ #0',\n",
    "                    [f'M == {i}' for i in range(1, M_REG_BLK)])\n",
    "        .simplify()\n",
    "        #\n",
    "        .replace_all(basic_kernel_Mx4[1])\n",
    "        .replace_all(basic_kernel_Mx4[2])\n",
    "        .replace_all(basic_kernel_Mx4[3])\n",
    "        .replace_all(basic_kernel_Mx4[4])\n",
    "        .replace_all(basic_kernel_Mx4[5])\n",
    "        #\n",
    "        .call_eqv(sgemm_kernel_avx512_Mx4[1], 'basic_kernel_1x4(_)')\n",
    "        .call_eqv(sgemm_kernel_avx512_Mx4[2], 'basic_kernel_2x4(_)')\n",
    "        .call_eqv(sgemm_kernel_avx512_Mx4[3], 'basic_kernel_3x4(_)')\n",
    "        .call_eqv(sgemm_kernel_avx512_Mx4[4], 'basic_kernel_4x4(_)')\n",
    "        .call_eqv(sgemm_kernel_avx512_Mx4[5], 'basic_kernel_5x4(_)')\n",
    "        #\n",
    "        .simplify()\n",
    ")\n",
    "print(bottom_panel_kernel_scheduled.c_code_str())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "specialize(pattern, [condition_lst])\n",
    "\n",
    "    creates special branches for each of the conditions in CONDITION_LST. Inserts above the statement that matches PATTERN. \n",
    "\n",
    "call_eqv(fn, pattern)\n",
    "\n",
    "    replaces function calls that match PATTERN with calls to FN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#include <stdint.h>\n",
      "#include <stdbool.h>\n",
      "\n",
      "// Compiler feature macros adapted from Hedley (public domain)\n",
      "// https://github.com/nemequ/hedley\n",
      "\n",
      "#if defined(__has_builtin)\n",
      "#  define EXO_HAS_BUILTIN(builtin) __has_builtin(builtin)\n",
      "#else\n",
      "#  define EXO_HAS_BUILTIN(builtin) (0)\n",
      "#endif\n",
      "\n",
      "#if EXO_HAS_BUILTIN(__builtin_assume)\n",
      "#  define EXO_ASSUME(expr) __builtin_assume(expr)\n",
      "#elif EXO_HAS_BUILTIN(__builtin_unreachable)\n",
      "#  define EXO_ASSUME(expr) \\\n",
      "      ((void)((expr) ? 1 : (__builtin_unreachable(), 1)))\n",
      "#else\n",
      "#  define EXO_ASSUME(expr) ((void)(expr))\n",
      "#endif\n",
      "\n",
      "struct exo_win_2f32{\n",
      "    float *data;\n",
      "    int_fast32_t strides[2];\n",
      "};\n",
      "typedef struct c_code_str_Context { \n",
      "\n",
      "} c_code_str_Context;\n",
      "\n",
      "\n",
      "// right_panel_kernel(\n",
      "//     N : size,\n",
      "//     K : size,\n",
      "//     A : [f32][6,K]  @DRAM,\n",
      "//     B : [f32][K,N]  @DRAM,\n",
      "//     C : [f32][6,N]  @DRAM\n",
      "// )\n",
      "void right_panel_kernel( c_code_str_Context *ctxt, int_fast32_t N, int_fast32_t K, struct exo_win_2f32 A, struct exo_win_2f32 B, struct exo_win_2f32 C );\n",
      "\n",
      "\n",
      "static int _floor_div(int num, int quot) {\n",
      "  int off = (num>=0)? 0 : quot-1;\n",
      "  return (num-off)/quot;\n",
      "}\n",
      "\n",
      "static int8_t _clamp_32to8(int32_t x) {\n",
      "  return (x < -128)? -128 : ((x > 127)? 127 : x);\n",
      "}\n",
      "\n",
      "#include <stdio.h>\n",
      "#include <stdlib.h>\n",
      "\n",
      "\n",
      "// right_panel_kernel(\n",
      "//     N : size,\n",
      "//     K : size,\n",
      "//     A : [f32][6,K]  @DRAM,\n",
      "//     B : [f32][K,N]  @DRAM,\n",
      "//     C : [f32][6,N]  @DRAM\n",
      "// )\n",
      "void right_panel_kernel( c_code_str_Context *ctxt, int_fast32_t N, int_fast32_t K, struct exo_win_2f32 A, struct exo_win_2f32 B, struct exo_win_2f32 C ) {\n",
      "EXO_ASSUME(N >= 1);\n",
      "EXO_ASSUME(K >= 1);\n",
      "EXO_ASSUME(A.strides[1] == 1);\n",
      "EXO_ASSUME(B.strides[1] == 1);\n",
      "EXO_ASSUME(C.strides[1] == 1);\n",
      "EXO_ASSUME(((N) / (16)) < 4);\n",
      "for (int k = 0; k < K; k++) {\n",
      "  for (int i = 0; i < 6; i++) {\n",
      "    for (int j = 0; j < N; j++) {\n",
      "      C.data[(i) * (C.strides[0]) + (j) * (C.strides[1])] += A.data[(i) * (A.strides[0]) + (k) * (A.strides[1])] * B.data[(k) * (B.strides[0]) + (j) * (B.strides[1])];\n",
      "    }\n",
      "  }\n",
      "}\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now for the right kernel\n",
    "# This one is basically just the microkernel (M_r*K_c and K_c*N_r), but it handles cases where M_r is the largest it can be (6 in this case)\n",
    "# There is a case for each possible value of N_r/VEC_W, or in other words, for how many vectors can fit into the register block\n",
    "# used for N.\n",
    "\n",
    "right_panel_kernel = (\n",
    "    SGEMM_WINDOW\n",
    "        .rename('right_panel_kernel')\n",
    "        .partial_eval(M=M_REG_BLK)\n",
    "        .add_assertion(f'N / {VEC_W} < 4')\n",
    "        .simplify()\n",
    ")\n",
    "print(right_panel_kernel.c_code_str())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#include <stdint.h>\n",
      "#include <stdbool.h>\n",
      "\n",
      "// Compiler feature macros adapted from Hedley (public domain)\n",
      "// https://github.com/nemequ/hedley\n",
      "\n",
      "#if defined(__has_builtin)\n",
      "#  define EXO_HAS_BUILTIN(builtin) __has_builtin(builtin)\n",
      "#else\n",
      "#  define EXO_HAS_BUILTIN(builtin) (0)\n",
      "#endif\n",
      "\n",
      "#if EXO_HAS_BUILTIN(__builtin_assume)\n",
      "#  define EXO_ASSUME(expr) __builtin_assume(expr)\n",
      "#elif EXO_HAS_BUILTIN(__builtin_unreachable)\n",
      "#  define EXO_ASSUME(expr) \\\n",
      "      ((void)((expr) ? 1 : (__builtin_unreachable(), 1)))\n",
      "#else\n",
      "#  define EXO_ASSUME(expr) ((void)(expr))\n",
      "#endif\n",
      "\n",
      "struct exo_win_2f32{\n",
      "    float *data;\n",
      "    int_fast32_t strides[2];\n",
      "};\n",
      "struct exo_win_1f32{\n",
      "    float *data;\n",
      "    int_fast32_t strides[1];\n",
      "};\n",
      "typedef struct c_code_str_Context { \n",
      "\n",
      "} c_code_str_Context;\n",
      "\n",
      "\n",
      "// right_panel_kernel_opt(\n",
      "//     N : size,\n",
      "//     K : size,\n",
      "//     A : [f32][6,K]  @DRAM,\n",
      "//     B : [f32][K,N]  @DRAM,\n",
      "//     C : [f32][6,N]  @DRAM\n",
      "// )\n",
      "void right_panel_kernel_opt( c_code_str_Context *ctxt, int_fast32_t N, int_fast32_t K, struct exo_win_2f32 A, struct exo_win_2f32 B, struct exo_win_2f32 C );\n",
      "\n",
      "\n",
      "static int _floor_div(int num, int quot) {\n",
      "  int off = (num>=0)? 0 : quot-1;\n",
      "  return (num-off)/quot;\n",
      "}\n",
      "\n",
      "static int8_t _clamp_32to8(int32_t x) {\n",
      "  return (x < -128)? -128 : ((x > 127)? 127 : x);\n",
      "}\n",
      "\n",
      "#include <immintrin.h>\n",
      "\n",
      "#include <stdio.h>\n",
      "#include <stdlib.h>\n",
      "\n",
      "\n",
      "\n",
      "/* relying on the following instruction...\n",
      "mm512_storeu_ps(dst,src)\n",
      "_mm512_storeu_ps(&{dst_data}, {src_data});\n",
      "*/\n",
      "\n",
      "\n",
      "/* relying on the following instruction...\n",
      "mm512_mask_fmadd_ps(N,A,B,C)\n",
      "{C_data} = _mm512_mask_fmadd_ps({A}, ((1 << {N}) - 1), {B}, {C_data});\n",
      "*/\n",
      "\n",
      "\n",
      "/* relying on the following instruction...\n",
      "mm512_set1_ps(dst,src)\n",
      "{dst} = _mm512_set1_ps({src_data});\n",
      "*/\n",
      "\n",
      "\n",
      "/* relying on the following instruction...\n",
      "mm512_loadu_ps(dst,src)\n",
      "{dst_data} = _mm512_loadu_ps(&{src_data});\n",
      "*/\n",
      "\n",
      "\n",
      "/* relying on the following instruction...\n",
      "mm512_mask_storeu_ps(N,dst,src)\n",
      "_mm512_mask_storeu_ps(&{dst_data}, ((1 << {N}) - 1), {src_data});\n",
      "*/\n",
      "\n",
      "\n",
      "/* relying on the following instruction...\n",
      "mm512_mask_set1_ps(N,dst,src)\n",
      "{dst} = _mm512_set1_ps({src_data});\n",
      "*/\n",
      "\n",
      "\n",
      "/* relying on the following instruction...\n",
      "mm512_maskz_loadu_ps(N,dst,src)\n",
      "{dst_data} = _mm512_maskz_loadu_ps(((1 << {N}) - 1), &{src_data});\n",
      "*/\n",
      "\n",
      "\n",
      "/* relying on the following instruction...\n",
      "mm512_fmadd_ps(A,B,C)\n",
      "{C_data} = _mm512_fmadd_ps({A}, {B}, {C_data});\n",
      "*/\n",
      "\n",
      "// right_panel_kernel_opt(\n",
      "//     N : size,\n",
      "//     K : size,\n",
      "//     A : [f32][6,K]  @DRAM,\n",
      "//     B : [f32][K,N]  @DRAM,\n",
      "//     C : [f32][6,N]  @DRAM\n",
      "// )\n",
      "void right_panel_kernel_opt( c_code_str_Context *ctxt, int_fast32_t N, int_fast32_t K, struct exo_win_2f32 A, struct exo_win_2f32 B, struct exo_win_2f32 C ) {\n",
      "EXO_ASSUME(N >= 1);\n",
      "EXO_ASSUME(K >= 1);\n",
      "EXO_ASSUME(A.strides[1] == 1);\n",
      "EXO_ASSUME(B.strides[1] == 1);\n",
      "EXO_ASSUME(C.strides[1] == 1);\n",
      "EXO_ASSUME(((N) / (16)) < 4);\n",
      "__m512 C_reg[6][(((N) / (16)) + 1)];\n",
      "__m512 C_reg_1[6];\n",
      "for (int i = 0; i < 6; i++) {\n",
      "  for (int jo = 0; jo < ((N) / (16)); jo++) {\n",
      "    C_reg[i][jo] = _mm512_loadu_ps(&C.data[(i) * (C.strides[0]) + (16 * jo) * (C.strides[1])]);\n",
      "  }\n",
      "  C_reg_1[i] = _mm512_maskz_loadu_ps(((1 << (N % 16)) - 1), &C.data[(i) * (C.strides[0]) + (16 * ((N) / (16))) * (C.strides[1])]);\n",
      "}\n",
      "for (int k = 0; k < K; k++) {\n",
      "  for (int i = 0; i < 6; i++) {\n",
      "    for (int jo = 0; jo < ((N) / (16)); jo++) {\n",
      "      __m512 A_reg;\n",
      "      (A_reg) = _mm512_set1_ps(A.data[(i) * (A.strides[0]) + (k) * (A.strides[1])]);\n",
      "      __m512 B_reg;\n",
      "      B_reg = _mm512_loadu_ps(&B.data[(k) * (B.strides[0]) + (16 * jo) * (B.strides[1])]);\n",
      "      C_reg[i][jo] = _mm512_fmadd_ps((A_reg), (B_reg), C_reg[i][jo]);\n",
      "    }\n",
      "    __m512 A_reg2;\n",
      "    (A_reg2) = _mm512_set1_ps(A.data[(i) * (A.strides[0]) + (k) * (A.strides[1])]);\n",
      "    __m512 B_reg2;\n",
      "    B_reg2 = _mm512_maskz_loadu_ps(((1 << (N % 16)) - 1), &B.data[(k) * (B.strides[0]) + (16 * ((N) / (16))) * (B.strides[1])]);\n",
      "    C_reg_1[i] = _mm512_mask_fmadd_ps((A_reg2), ((1 << (N % 16)) - 1), (B_reg2), C_reg_1[i]);\n",
      "  }\n",
      "}\n",
      "for (int i = 0; i < 6; i++) {\n",
      "  for (int jo = 0; jo < ((N) / (16)); jo++) {\n",
      "    _mm512_storeu_ps(&C.data[(i) * (C.strides[0]) + (16 * jo) * (C.strides[1])], C_reg[i][jo]);\n",
      "  }\n",
      "  _mm512_mask_storeu_ps(&C.data[(i) * (C.strides[0]) + (16 * ((N) / (16))) * (C.strides[1])], ((1 << (N % 16)) - 1), C_reg_1[i]);\n",
      "}\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "right_panel_kernel_opt = (\n",
    "    right_panel_kernel\n",
    "        .rename('right_panel_kernel_opt')\n",
    "        #\n",
    "        .stage_assn('C_reg', 'C[_] += _')\n",
    "        .split('j', VEC_W, ['jo', 'ji'], tail='cut')\n",
    "        .bound_and_guard('for ji in _: _ #1')\n",
    "        .fission_after('for jo in _: _', n_lifts=2)\n",
    "        #\n",
    "        .par_to_seq('for k in _: _')\n",
    "        #\n",
    "        .lift_alloc('C_reg: _', n_lifts=4)\n",
    "        .reorder_before('C_reg: _ #1')\n",
    "        #\n",
    "        .fission_after('C_reg[_] = _', n_lifts=4)\n",
    "        .fission_after('C_reg[_] += _', n_lifts=4)\n",
    "        #\n",
    "        .reorder_before('for i in _: _ #3')\n",
    "        .reorder_before('for i in _: _ #2')\n",
    "        #\n",
    "        .reorder_before('for k in _: _ #1')\n",
    "        #\n",
    "        .set_memory('C_reg', AVX512)\n",
    "        #\n",
    "        .stage_expr('A_reg', 'A[_]', memory=AVX512)\n",
    "        .stage_expr('B_reg', 'B[_]', memory=AVX512)\n",
    "        #\n",
    "        .replace_all(mm512_set1_ps)\n",
    "        .replace_all(mm512_fmadd_ps)\n",
    "        .replace(mm512_loadu_ps, 'for ji in _: _ #0')\n",
    "        .replace(mm512_loadu_ps, 'for ji in _: _ #1')\n",
    "        .replace(mm512_storeu_ps, 'for ji in _: _ #2')\n",
    "        #\n",
    "        .replace(mm512_maskz_loadu_ps, 'for ji in _: _ #0')\n",
    "        .replace(mm512_mask_storeu_ps, 'for ji in _: _ #1')\n",
    "        #\n",
    "        .stage_expr('A_reg2', 'A[_] #1', memory=AVX512, n_lifts=2)\n",
    "        .stage_expr('B_reg2', 'B[_] #1', memory=AVX512, n_lifts=2)\n",
    "        #\n",
    "        .replace_all(mm512_mask_set1_ps)\n",
    "        .replace_all(mm512_mask_fmadd_ps)\n",
    "        .replace_all(mm512_maskz_loadu_ps)\n",
    "        #\n",
    "        .fuse_loop('for i in _: _ #0', 'for i in _: _ #1')\n",
    "        .fuse_loop('for k in _: _ #0', 'for k in _: _ #1')\n",
    "        .fuse_loop('for i in _: _ #1', 'for i in _: _ #2')\n",
    "        .fuse_loop('for i in _: _ #2', 'for i in _: _ #3')\n",
    "        #\n",
    "        .simplify()\n",
    ")\n",
    "print(right_panel_kernel_opt.c_code_str())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fission_after(pattern, n_lifts)\n",
    "\n",
    "    copies the code below the loop identified by PATTERN, moves it N_LIFTS\n",
    "    loops outside of its original location, and places it at the bottom of the last\n",
    "    loop it was moved out of\n",
    "    \n",
    "\n",
    "bound_and_guard(pattern)\n",
    "\n",
    "    Finds the loop identified by PATTERN and creates a loop below it that TODO    \n",
    "\n",
    "reorder_before(pattern)\n",
    "\n",
    "    Slightly confused by this one. My best guess is that it creates a copy of PATTERN and replaces the identified numerical reference to PATTERN (the #N thing) with the copy of PATTERN. This is what it does when PATTERN is a memory allocation statement.\n",
    "\n",
    "    When PATTERN is a loop, it matches the #Nth instance of the loop, and moves it one loop above its current position.\n",
    "\n",
    "stage_expr(name, pattern, memory, n_lifts)\n",
    "\n",
    "    Matches the #Nth occurance of PATTERN and create an expression that loads it into NAME, which is located in MEMORY (like AVX512 for example). \n",
    "    N_LIFTS determines how many loops the memory allocation and the expression are lifted up out of, similar to other applications of N_LIFTS \n",
    "\n",
    "fuse_loop(loop1, loop2)\n",
    "\n",
    "    Fuses the body of loop1 with loop2, so now both bodies execute inside of a single loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#include <stdint.h>\n",
      "#include <stdbool.h>\n",
      "\n",
      "// Compiler feature macros adapted from Hedley (public domain)\n",
      "// https://github.com/nemequ/hedley\n",
      "\n",
      "#if defined(__has_builtin)\n",
      "#  define EXO_HAS_BUILTIN(builtin) __has_builtin(builtin)\n",
      "#else\n",
      "#  define EXO_HAS_BUILTIN(builtin) (0)\n",
      "#endif\n",
      "\n",
      "#if EXO_HAS_BUILTIN(__builtin_assume)\n",
      "#  define EXO_ASSUME(expr) __builtin_assume(expr)\n",
      "#elif EXO_HAS_BUILTIN(__builtin_unreachable)\n",
      "#  define EXO_ASSUME(expr) \\\n",
      "      ((void)((expr) ? 1 : (__builtin_unreachable(), 1)))\n",
      "#else\n",
      "#  define EXO_ASSUME(expr) ((void)(expr))\n",
      "#endif\n",
      "\n",
      "struct exo_win_2f32{\n",
      "    float *data;\n",
      "    int_fast32_t strides[2];\n",
      "};\n",
      "struct exo_win_1f32{\n",
      "    float *data;\n",
      "    int_fast32_t strides[1];\n",
      "};\n",
      "typedef struct c_code_str_Context { \n",
      "\n",
      "} c_code_str_Context;\n",
      "\n",
      "\n",
      "// right_panel_kernel_scheduled(\n",
      "//     N : size,\n",
      "//     K : size,\n",
      "//     A : [f32][6,K]  @DRAM,\n",
      "//     B : [f32][K,N]  @DRAM,\n",
      "//     C : [f32][6,N]  @DRAM\n",
      "// )\n",
      "void right_panel_kernel_scheduled( c_code_str_Context *ctxt, int_fast32_t N, int_fast32_t K, struct exo_win_2f32 A, struct exo_win_2f32 B, struct exo_win_2f32 C );\n",
      "\n",
      "\n",
      "static int _floor_div(int num, int quot) {\n",
      "  int off = (num>=0)? 0 : quot-1;\n",
      "  return (num-off)/quot;\n",
      "}\n",
      "\n",
      "static int8_t _clamp_32to8(int32_t x) {\n",
      "  return (x < -128)? -128 : ((x > 127)? 127 : x);\n",
      "}\n",
      "\n",
      "#include <immintrin.h>\n",
      "\n",
      "#include <stdio.h>\n",
      "#include <stdlib.h>\n",
      "\n",
      "\n",
      "\n",
      "/* relying on the following instruction...\n",
      "mm512_storeu_ps(dst,src)\n",
      "_mm512_storeu_ps(&{dst_data}, {src_data});\n",
      "*/\n",
      "\n",
      "\n",
      "/* relying on the following instruction...\n",
      "mm512_set1_ps(dst,src)\n",
      "{dst} = _mm512_set1_ps({src_data});\n",
      "*/\n",
      "\n",
      "\n",
      "/* relying on the following instruction...\n",
      "mm512_mask_fmadd_ps(N,A,B,C)\n",
      "{C_data} = _mm512_mask_fmadd_ps({A}, ((1 << {N}) - 1), {B}, {C_data});\n",
      "*/\n",
      "\n",
      "\n",
      "/* relying on the following instruction...\n",
      "mm512_loadu_ps(dst,src)\n",
      "{dst_data} = _mm512_loadu_ps(&{src_data});\n",
      "*/\n",
      "\n",
      "\n",
      "/* relying on the following instruction...\n",
      "mm512_fmadd_ps(A,B,C)\n",
      "{C_data} = _mm512_fmadd_ps({A}, {B}, {C_data});\n",
      "*/\n",
      "\n",
      "\n",
      "/* relying on the following instruction...\n",
      "mm512_mask_storeu_ps(N,dst,src)\n",
      "_mm512_mask_storeu_ps(&{dst_data}, ((1 << {N}) - 1), {src_data});\n",
      "*/\n",
      "\n",
      "\n",
      "/* relying on the following instruction...\n",
      "mm512_mask_set1_ps(N,dst,src)\n",
      "{dst} = _mm512_set1_ps({src_data});\n",
      "*/\n",
      "\n",
      "\n",
      "/* relying on the following instruction...\n",
      "mm512_maskz_loadu_ps(N,dst,src)\n",
      "{dst_data} = _mm512_maskz_loadu_ps(((1 << {N}) - 1), &{src_data});\n",
      "*/\n",
      "\n",
      "// right_panel_kernel_scheduled(\n",
      "//     N : size,\n",
      "//     K : size,\n",
      "//     A : [f32][6,K]  @DRAM,\n",
      "//     B : [f32][K,N]  @DRAM,\n",
      "//     C : [f32][6,N]  @DRAM\n",
      "// )\n",
      "void right_panel_kernel_scheduled( c_code_str_Context *ctxt, int_fast32_t N, int_fast32_t K, struct exo_win_2f32 A, struct exo_win_2f32 B, struct exo_win_2f32 C ) {\n",
      "EXO_ASSUME(N >= 1);\n",
      "EXO_ASSUME(K >= 1);\n",
      "EXO_ASSUME(A.strides[1] == 1);\n",
      "EXO_ASSUME(B.strides[1] == 1);\n",
      "EXO_ASSUME(C.strides[1] == 1);\n",
      "EXO_ASSUME(((N) / (16)) < 4);\n",
      "if (((N) / (16)) == 0) {\n",
      "  __m512 C_reg[6][1];\n",
      "  __m512 C_reg_1[6];\n",
      "  for (int i = 0; i < 6; i++) {\n",
      "    C_reg_1[i] = _mm512_maskz_loadu_ps(((1 << (N)) - 1), &C.data[(i) * (C.strides[0]) + (0) * (C.strides[1])]);\n",
      "  }\n",
      "  for (int k = 0; k < K; k++) {\n",
      "    for (int i = 0; i < 6; i++) {\n",
      "      __m512 A_reg2;\n",
      "      (A_reg2) = _mm512_set1_ps(A.data[(i) * (A.strides[0]) + (k) * (A.strides[1])]);\n",
      "      __m512 B_reg2;\n",
      "      B_reg2 = _mm512_maskz_loadu_ps(((1 << (N)) - 1), &B.data[(k) * (B.strides[0]) + (0) * (B.strides[1])]);\n",
      "      C_reg_1[i] = _mm512_mask_fmadd_ps((A_reg2), ((1 << (N)) - 1), (B_reg2), C_reg_1[i]);\n",
      "    }\n",
      "  }\n",
      "  for (int i = 0; i < 6; i++) {\n",
      "    _mm512_mask_storeu_ps(&C.data[(i) * (C.strides[0]) + (0) * (C.strides[1])], ((1 << (N)) - 1), C_reg_1[i]);\n",
      "  }\n",
      "} else {\n",
      "  if (((N) / (16)) == 1) {\n",
      "    __m512 C_reg[6][2];\n",
      "    __m512 C_reg_1[6];\n",
      "    for (int i = 0; i < 6; i++) {\n",
      "      for (int jo = 0; jo < 1; jo++) {\n",
      "        C_reg[i][jo] = _mm512_loadu_ps(&C.data[(i) * (C.strides[0]) + (16 * jo) * (C.strides[1])]);\n",
      "      }\n",
      "      C_reg_1[i] = _mm512_maskz_loadu_ps(((1 << (N % 16)) - 1), &C.data[(i) * (C.strides[0]) + (16) * (C.strides[1])]);\n",
      "    }\n",
      "    for (int k = 0; k < K; k++) {\n",
      "      for (int i = 0; i < 6; i++) {\n",
      "        for (int jo = 0; jo < 1; jo++) {\n",
      "          __m512 A_reg;\n",
      "          (A_reg) = _mm512_set1_ps(A.data[(i) * (A.strides[0]) + (k) * (A.strides[1])]);\n",
      "          __m512 B_reg;\n",
      "          B_reg = _mm512_loadu_ps(&B.data[(k) * (B.strides[0]) + (16 * jo) * (B.strides[1])]);\n",
      "          C_reg[i][jo] = _mm512_fmadd_ps((A_reg), (B_reg), C_reg[i][jo]);\n",
      "        }\n",
      "        __m512 A_reg2;\n",
      "        (A_reg2) = _mm512_set1_ps(A.data[(i) * (A.strides[0]) + (k) * (A.strides[1])]);\n",
      "        __m512 B_reg2;\n",
      "        B_reg2 = _mm512_maskz_loadu_ps(((1 << (N % 16)) - 1), &B.data[(k) * (B.strides[0]) + (16) * (B.strides[1])]);\n",
      "        C_reg_1[i] = _mm512_mask_fmadd_ps((A_reg2), ((1 << (N % 16)) - 1), (B_reg2), C_reg_1[i]);\n",
      "      }\n",
      "    }\n",
      "    for (int i = 0; i < 6; i++) {\n",
      "      for (int jo = 0; jo < 1; jo++) {\n",
      "        _mm512_storeu_ps(&C.data[(i) * (C.strides[0]) + (16 * jo) * (C.strides[1])], C_reg[i][jo]);\n",
      "      }\n",
      "      _mm512_mask_storeu_ps(&C.data[(i) * (C.strides[0]) + (16) * (C.strides[1])], ((1 << (N % 16)) - 1), C_reg_1[i]);\n",
      "    }\n",
      "  } else {\n",
      "    if (((N) / (16)) == 2) {\n",
      "      __m512 C_reg[6][3];\n",
      "      __m512 C_reg_1[6];\n",
      "      for (int i = 0; i < 6; i++) {\n",
      "        for (int jo = 0; jo < 2; jo++) {\n",
      "          C_reg[i][jo] = _mm512_loadu_ps(&C.data[(i) * (C.strides[0]) + (16 * jo) * (C.strides[1])]);\n",
      "        }\n",
      "        C_reg_1[i] = _mm512_maskz_loadu_ps(((1 << (N % 16)) - 1), &C.data[(i) * (C.strides[0]) + (32) * (C.strides[1])]);\n",
      "      }\n",
      "      for (int k = 0; k < K; k++) {\n",
      "        for (int i = 0; i < 6; i++) {\n",
      "          for (int jo = 0; jo < 2; jo++) {\n",
      "            __m512 A_reg;\n",
      "            (A_reg) = _mm512_set1_ps(A.data[(i) * (A.strides[0]) + (k) * (A.strides[1])]);\n",
      "            __m512 B_reg;\n",
      "            B_reg = _mm512_loadu_ps(&B.data[(k) * (B.strides[0]) + (16 * jo) * (B.strides[1])]);\n",
      "            C_reg[i][jo] = _mm512_fmadd_ps((A_reg), (B_reg), C_reg[i][jo]);\n",
      "          }\n",
      "          __m512 A_reg2;\n",
      "          (A_reg2) = _mm512_set1_ps(A.data[(i) * (A.strides[0]) + (k) * (A.strides[1])]);\n",
      "          __m512 B_reg2;\n",
      "          B_reg2 = _mm512_maskz_loadu_ps(((1 << (N % 16)) - 1), &B.data[(k) * (B.strides[0]) + (32) * (B.strides[1])]);\n",
      "          C_reg_1[i] = _mm512_mask_fmadd_ps((A_reg2), ((1 << (N % 16)) - 1), (B_reg2), C_reg_1[i]);\n",
      "        }\n",
      "      }\n",
      "      for (int i = 0; i < 6; i++) {\n",
      "        for (int jo = 0; jo < 2; jo++) {\n",
      "          _mm512_storeu_ps(&C.data[(i) * (C.strides[0]) + (16 * jo) * (C.strides[1])], C_reg[i][jo]);\n",
      "        }\n",
      "        _mm512_mask_storeu_ps(&C.data[(i) * (C.strides[0]) + (32) * (C.strides[1])], ((1 << (N % 16)) - 1), C_reg_1[i]);\n",
      "      }\n",
      "    } else {\n",
      "      if (((N) / (16)) == 3) {\n",
      "        __m512 C_reg[6][4];\n",
      "        __m512 C_reg_1[6];\n",
      "        for (int i = 0; i < 6; i++) {\n",
      "          for (int jo = 0; jo < 3; jo++) {\n",
      "            C_reg[i][jo] = _mm512_loadu_ps(&C.data[(i) * (C.strides[0]) + (16 * jo) * (C.strides[1])]);\n",
      "          }\n",
      "          C_reg_1[i] = _mm512_maskz_loadu_ps(((1 << (N % 16)) - 1), &C.data[(i) * (C.strides[0]) + (48) * (C.strides[1])]);\n",
      "        }\n",
      "        for (int k = 0; k < K; k++) {\n",
      "          for (int i = 0; i < 6; i++) {\n",
      "            for (int jo = 0; jo < 3; jo++) {\n",
      "              __m512 A_reg;\n",
      "              (A_reg) = _mm512_set1_ps(A.data[(i) * (A.strides[0]) + (k) * (A.strides[1])]);\n",
      "              __m512 B_reg;\n",
      "              B_reg = _mm512_loadu_ps(&B.data[(k) * (B.strides[0]) + (16 * jo) * (B.strides[1])]);\n",
      "              C_reg[i][jo] = _mm512_fmadd_ps((A_reg), (B_reg), C_reg[i][jo]);\n",
      "            }\n",
      "            __m512 A_reg2;\n",
      "            (A_reg2) = _mm512_set1_ps(A.data[(i) * (A.strides[0]) + (k) * (A.strides[1])]);\n",
      "            __m512 B_reg2;\n",
      "            B_reg2 = _mm512_maskz_loadu_ps(((1 << (N % 16)) - 1), &B.data[(k) * (B.strides[0]) + (48) * (B.strides[1])]);\n",
      "            C_reg_1[i] = _mm512_mask_fmadd_ps((A_reg2), ((1 << (N % 16)) - 1), (B_reg2), C_reg_1[i]);\n",
      "          }\n",
      "        }\n",
      "        for (int i = 0; i < 6; i++) {\n",
      "          for (int jo = 0; jo < 3; jo++) {\n",
      "            _mm512_storeu_ps(&C.data[(i) * (C.strides[0]) + (16 * jo) * (C.strides[1])], C_reg[i][jo]);\n",
      "          }\n",
      "          _mm512_mask_storeu_ps(&C.data[(i) * (C.strides[0]) + (48) * (C.strides[1])], ((1 << (N % 16)) - 1), C_reg_1[i]);\n",
      "        }\n",
      "      } else {\n",
      "        __m512 C_reg[6][(((N) / (16)) + 1)];\n",
      "        __m512 C_reg_1[6];\n",
      "        for (int i = 0; i < 6; i++) {\n",
      "          for (int jo = 0; jo < ((N) / (16)); jo++) {\n",
      "            C_reg[i][jo] = _mm512_loadu_ps(&C.data[(i) * (C.strides[0]) + (16 * jo) * (C.strides[1])]);\n",
      "          }\n",
      "          C_reg_1[i] = _mm512_maskz_loadu_ps(((1 << (N % 16)) - 1), &C.data[(i) * (C.strides[0]) + (16 * ((N) / (16))) * (C.strides[1])]);\n",
      "        }\n",
      "        for (int k = 0; k < K; k++) {\n",
      "          for (int i = 0; i < 6; i++) {\n",
      "            for (int jo = 0; jo < ((N) / (16)); jo++) {\n",
      "              __m512 A_reg;\n",
      "              (A_reg) = _mm512_set1_ps(A.data[(i) * (A.strides[0]) + (k) * (A.strides[1])]);\n",
      "              __m512 B_reg;\n",
      "              B_reg = _mm512_loadu_ps(&B.data[(k) * (B.strides[0]) + (16 * jo) * (B.strides[1])]);\n",
      "              C_reg[i][jo] = _mm512_fmadd_ps((A_reg), (B_reg), C_reg[i][jo]);\n",
      "            }\n",
      "            __m512 A_reg2;\n",
      "            (A_reg2) = _mm512_set1_ps(A.data[(i) * (A.strides[0]) + (k) * (A.strides[1])]);\n",
      "            __m512 B_reg2;\n",
      "            B_reg2 = _mm512_maskz_loadu_ps(((1 << (N % 16)) - 1), &B.data[(k) * (B.strides[0]) + (16 * ((N) / (16))) * (B.strides[1])]);\n",
      "            C_reg_1[i] = _mm512_mask_fmadd_ps((A_reg2), ((1 << (N % 16)) - 1), (B_reg2), C_reg_1[i]);\n",
      "          }\n",
      "        }\n",
      "        for (int i = 0; i < 6; i++) {\n",
      "          for (int jo = 0; jo < ((N) / (16)); jo++) {\n",
      "            _mm512_storeu_ps(&C.data[(i) * (C.strides[0]) + (16 * jo) * (C.strides[1])], C_reg[i][jo]);\n",
      "          }\n",
      "          _mm512_mask_storeu_ps(&C.data[(i) * (C.strides[0]) + (16 * ((N) / (16))) * (C.strides[1])], ((1 << (N % 16)) - 1), C_reg_1[i]);\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This handles the possible N_r/VEC_W values and creates inline calls to the right_panel_kernel for each case.\n",
    "right_panel_kernel_scheduled = (\n",
    "    right_panel_kernel\n",
    "        .rename('right_panel_kernel_scheduled')\n",
    "        #\n",
    "        .replace_all(right_panel_kernel)\n",
    "        #\n",
    "        .specialize('right_panel_kernel(_) #0',\n",
    "                    [f'(N / {VEC_W}) == {i}' for i in range(N_REG_BLK // VEC_W)])\n",
    "        #\n",
    "        .repeat(Procedure.call_eqv, right_panel_kernel_opt,\n",
    "                'right_panel_kernel(_)')\n",
    "        .repeat(Procedure.inline, 'right_panel_kernel_opt(_)')\n",
    "        #\n",
    "        .simplify()\n",
    "        #\n",
    "        .repeat(Procedure.inline_window, 'A = _')\n",
    "        .repeat(Procedure.inline_window, 'B = _')\n",
    "        .repeat(Procedure.inline_window, 'C = _')\n",
    "        #\n",
    "        .simplify()\n",
    ")\n",
    "print(right_panel_kernel_scheduled.c_code_str())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "repeat(Procedure.fn, arg, pattern)\n",
    "\n",
    "    Calls PATTERN.FN(ARG) on every match of PATTERN. To be clear, each match of PATTERN is set equal to the Procedure instance that FN is called upon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#include <stdint.h>\n",
      "#include <stdbool.h>\n",
      "\n",
      "// Compiler feature macros adapted from Hedley (public domain)\n",
      "// https://github.com/nemequ/hedley\n",
      "\n",
      "#if defined(__has_builtin)\n",
      "#  define EXO_HAS_BUILTIN(builtin) __has_builtin(builtin)\n",
      "#else\n",
      "#  define EXO_HAS_BUILTIN(builtin) (0)\n",
      "#endif\n",
      "\n",
      "#if EXO_HAS_BUILTIN(__builtin_assume)\n",
      "#  define EXO_ASSUME(expr) __builtin_assume(expr)\n",
      "#elif EXO_HAS_BUILTIN(__builtin_unreachable)\n",
      "#  define EXO_ASSUME(expr) \\\n",
      "      ((void)((expr) ? 1 : (__builtin_unreachable(), 1)))\n",
      "#else\n",
      "#  define EXO_ASSUME(expr) ((void)(expr))\n",
      "#endif\n",
      "\n",
      "struct exo_win_2f32{\n",
      "    float *data;\n",
      "    int_fast32_t strides[2];\n",
      "};\n",
      "struct exo_win_1f32{\n",
      "    float *data;\n",
      "    int_fast32_t strides[1];\n",
      "};\n",
      "typedef struct c_code_str_Context { \n",
      "\n",
      "} c_code_str_Context;\n",
      "\n",
      "\n",
      "// sgemm_above_kernel(\n",
      "//     M : size,\n",
      "//     N : size,\n",
      "//     K : size,\n",
      "//     A : [f32][M,K]  @DRAM,\n",
      "//     B : [f32][K,N]  @DRAM,\n",
      "//     C : [f32][M,N]  @DRAM\n",
      "// )\n",
      "void sgemm_above_kernel( c_code_str_Context *ctxt, int_fast32_t M, int_fast32_t N, int_fast32_t K, struct exo_win_2f32 A, struct exo_win_2f32 B, struct exo_win_2f32 C );\n",
      "\n",
      "\n",
      "static int _floor_div(int num, int quot) {\n",
      "  int off = (num>=0)? 0 : quot-1;\n",
      "  return (num-off)/quot;\n",
      "}\n",
      "\n",
      "static int8_t _clamp_32to8(int32_t x) {\n",
      "  return (x < -128)? -128 : ((x > 127)? 127 : x);\n",
      "}\n",
      "\n",
      "#include <immintrin.h>\n",
      "\n",
      "#include <stdio.h>\n",
      "#include <stdlib.h>\n",
      "\n",
      "\n",
      "// right_panel_kernel(\n",
      "//     N : size,\n",
      "//     K : size,\n",
      "//     A : [f32][6,K]  @DRAM,\n",
      "//     B : [f32][K,N]  @DRAM,\n",
      "//     C : [f32][6,N]  @DRAM\n",
      "// )\n",
      "void right_panel_kernel( c_code_str_Context *ctxt, int_fast32_t N, int_fast32_t K, struct exo_win_2f32 A, struct exo_win_2f32 B, struct exo_win_2f32 C ) {\n",
      "EXO_ASSUME(N >= 1);\n",
      "EXO_ASSUME(K >= 1);\n",
      "EXO_ASSUME(A.strides[1] == 1);\n",
      "EXO_ASSUME(B.strides[1] == 1);\n",
      "EXO_ASSUME(C.strides[1] == 1);\n",
      "EXO_ASSUME(((N) / (16)) < 4);\n",
      "for (int k = 0; k < K; k++) {\n",
      "  for (int i = 0; i < 6; i++) {\n",
      "    for (int j = 0; j < N; j++) {\n",
      "      C.data[(i) * (C.strides[0]) + (j) * (C.strides[1])] += A.data[(i) * (A.strides[0]) + (k) * (A.strides[1])] * B.data[(k) * (B.strides[0]) + (j) * (B.strides[1])];\n",
      "    }\n",
      "  }\n",
      "}\n",
      "}\n",
      "\n",
      "// right_panel_kernel_scheduled(\n",
      "//     N : size,\n",
      "//     K : size,\n",
      "//     A : [f32][6,K]  @DRAM,\n",
      "//     B : [f32][K,N]  @DRAM,\n",
      "//     C : [f32][6,N]  @DRAM\n",
      "// )\n",
      "void right_panel_kernel_scheduled( c_code_str_Context *ctxt, int_fast32_t N, int_fast32_t K, struct exo_win_2f32 A, struct exo_win_2f32 B, struct exo_win_2f32 C ) {\n",
      "EXO_ASSUME(N >= 1);\n",
      "EXO_ASSUME(K >= 1);\n",
      "EXO_ASSUME(A.strides[1] == 1);\n",
      "EXO_ASSUME(B.strides[1] == 1);\n",
      "EXO_ASSUME(C.strides[1] == 1);\n",
      "EXO_ASSUME(((N) / (16)) < 4);\n",
      "if (((N) / (16)) == 0) {\n",
      "  right_panel_kernel(ctxt,N,K,(struct exo_win_2f32){ (float*)&A.data[(0) * (A.strides[0]) + (0) * (A.strides[1])], { A.strides[0], A.strides[1] } },(struct exo_win_2f32){ (float*)&B.data[(0) * (B.strides[0]) + (0) * (B.strides[1])], { B.strides[0], B.strides[1] } },(struct exo_win_2f32){ (float*)&C.data[(0) * (C.strides[0]) + (0) * (C.strides[1])], { C.strides[0], C.strides[1] } });\n",
      "} else {\n",
      "  if (((N) / (16)) == 1) {\n",
      "    right_panel_kernel(ctxt,N,K,(struct exo_win_2f32){ (float*)&A.data[(0) * (A.strides[0]) + (0) * (A.strides[1])], { A.strides[0], A.strides[1] } },(struct exo_win_2f32){ (float*)&B.data[(0) * (B.strides[0]) + (0) * (B.strides[1])], { B.strides[0], B.strides[1] } },(struct exo_win_2f32){ (float*)&C.data[(0) * (C.strides[0]) + (0) * (C.strides[1])], { C.strides[0], C.strides[1] } });\n",
      "  } else {\n",
      "    if (((N) / (16)) == 2) {\n",
      "      right_panel_kernel(ctxt,N,K,(struct exo_win_2f32){ (float*)&A.data[(0) * (A.strides[0]) + (0) * (A.strides[1])], { A.strides[0], A.strides[1] } },(struct exo_win_2f32){ (float*)&B.data[(0) * (B.strides[0]) + (0) * (B.strides[1])], { B.strides[0], B.strides[1] } },(struct exo_win_2f32){ (float*)&C.data[(0) * (C.strides[0]) + (0) * (C.strides[1])], { C.strides[0], C.strides[1] } });\n",
      "    } else {\n",
      "      if (((N) / (16)) == 3) {\n",
      "        right_panel_kernel(ctxt,N,K,(struct exo_win_2f32){ (float*)&A.data[(0) * (A.strides[0]) + (0) * (A.strides[1])], { A.strides[0], A.strides[1] } },(struct exo_win_2f32){ (float*)&B.data[(0) * (B.strides[0]) + (0) * (B.strides[1])], { B.strides[0], B.strides[1] } },(struct exo_win_2f32){ (float*)&C.data[(0) * (C.strides[0]) + (0) * (C.strides[1])], { C.strides[0], C.strides[1] } });\n",
      "      } else {\n",
      "        right_panel_kernel(ctxt,N,K,(struct exo_win_2f32){ (float*)&A.data[(0) * (A.strides[0]) + (0) * (A.strides[1])], { A.strides[0], A.strides[1] } },(struct exo_win_2f32){ (float*)&B.data[(0) * (B.strides[0]) + (0) * (B.strides[1])], { B.strides[0], B.strides[1] } },(struct exo_win_2f32){ (float*)&C.data[(0) * (C.strides[0]) + (0) * (C.strides[1])], { C.strides[0], C.strides[1] } });\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "}\n",
      "\n",
      "// sgemm_kernel_avx512_4x4(\n",
      "//     K : size,\n",
      "//     A : [f32][4,K]  @DRAM,\n",
      "//     B : [f32][K,64]  @DRAM,\n",
      "//     C : [f32][4,64]  @DRAM\n",
      "// )\n",
      "void sgemm_kernel_avx512_4x4( c_code_str_Context *ctxt, int_fast32_t K, struct exo_win_2f32 A, struct exo_win_2f32 B, struct exo_win_2f32 C ) {\n",
      "EXO_ASSUME(K >= 1);\n",
      "EXO_ASSUME(A.strides[1] == 1);\n",
      "EXO_ASSUME(B.strides[1] == 1);\n",
      "EXO_ASSUME(C.strides[1] == 1);\n",
      "__m512 C_reg[4][4];\n",
      "for (int i = 0; i < 4; i++) {\n",
      "  for (int jo = 0; jo < 4; jo++) {\n",
      "    C_reg[i][jo] = _mm512_loadu_ps(&C.data[(i) * (C.strides[0]) + (16 * jo) * (C.strides[1])]);\n",
      "  }\n",
      "}\n",
      "for (int k = 0; k < K; k++) {\n",
      "  for (int i = 0; i < 4; i++) {\n",
      "    __m512 A_vec;\n",
      "    (A_vec) = _mm512_set1_ps(A.data[(i) * (A.strides[0]) + (k) * (A.strides[1])]);\n",
      "    for (int jo = 0; jo < 4; jo++) {\n",
      "      __m512 B_vec;\n",
      "      B_vec = _mm512_loadu_ps(&B.data[(k) * (B.strides[0]) + (16 * jo) * (B.strides[1])]);\n",
      "      C_reg[i][jo] = _mm512_fmadd_ps((A_vec), (B_vec), C_reg[i][jo]);\n",
      "    }\n",
      "  }\n",
      "}\n",
      "for (int i = 0; i < 4; i++) {\n",
      "  for (int jo = 0; jo < 4; jo++) {\n",
      "    _mm512_storeu_ps(&C.data[(i) * (C.strides[0]) + (16 * jo) * (C.strides[1])], C_reg[i][jo]);\n",
      "  }\n",
      "}\n",
      "}\n",
      "\n",
      "// sgemm_kernel_avx512_3x4(\n",
      "//     K : size,\n",
      "//     A : [f32][3,K]  @DRAM,\n",
      "//     B : [f32][K,64]  @DRAM,\n",
      "//     C : [f32][3,64]  @DRAM\n",
      "// )\n",
      "void sgemm_kernel_avx512_3x4( c_code_str_Context *ctxt, int_fast32_t K, struct exo_win_2f32 A, struct exo_win_2f32 B, struct exo_win_2f32 C ) {\n",
      "EXO_ASSUME(K >= 1);\n",
      "EXO_ASSUME(A.strides[1] == 1);\n",
      "EXO_ASSUME(B.strides[1] == 1);\n",
      "EXO_ASSUME(C.strides[1] == 1);\n",
      "__m512 C_reg[3][4];\n",
      "for (int i = 0; i < 3; i++) {\n",
      "  for (int jo = 0; jo < 4; jo++) {\n",
      "    C_reg[i][jo] = _mm512_loadu_ps(&C.data[(i) * (C.strides[0]) + (16 * jo) * (C.strides[1])]);\n",
      "  }\n",
      "}\n",
      "for (int k = 0; k < K; k++) {\n",
      "  for (int i = 0; i < 3; i++) {\n",
      "    __m512 A_vec;\n",
      "    (A_vec) = _mm512_set1_ps(A.data[(i) * (A.strides[0]) + (k) * (A.strides[1])]);\n",
      "    for (int jo = 0; jo < 4; jo++) {\n",
      "      __m512 B_vec;\n",
      "      B_vec = _mm512_loadu_ps(&B.data[(k) * (B.strides[0]) + (16 * jo) * (B.strides[1])]);\n",
      "      C_reg[i][jo] = _mm512_fmadd_ps((A_vec), (B_vec), C_reg[i][jo]);\n",
      "    }\n",
      "  }\n",
      "}\n",
      "for (int i = 0; i < 3; i++) {\n",
      "  for (int jo = 0; jo < 4; jo++) {\n",
      "    _mm512_storeu_ps(&C.data[(i) * (C.strides[0]) + (16 * jo) * (C.strides[1])], C_reg[i][jo]);\n",
      "  }\n",
      "}\n",
      "}\n",
      "\n",
      "// sgemm_kernel_avx512_1x4(\n",
      "//     K : size,\n",
      "//     A : [f32][1,K]  @DRAM,\n",
      "//     B : [f32][K,64]  @DRAM,\n",
      "//     C : [f32][1,64]  @DRAM\n",
      "// )\n",
      "void sgemm_kernel_avx512_1x4( c_code_str_Context *ctxt, int_fast32_t K, struct exo_win_2f32 A, struct exo_win_2f32 B, struct exo_win_2f32 C ) {\n",
      "EXO_ASSUME(K >= 1);\n",
      "EXO_ASSUME(A.strides[1] == 1);\n",
      "EXO_ASSUME(B.strides[1] == 1);\n",
      "EXO_ASSUME(C.strides[1] == 1);\n",
      "__m512 C_reg[1][4];\n",
      "for (int i = 0; i < 1; i++) {\n",
      "  for (int jo = 0; jo < 4; jo++) {\n",
      "    C_reg[i][jo] = _mm512_loadu_ps(&C.data[(i) * (C.strides[0]) + (16 * jo) * (C.strides[1])]);\n",
      "  }\n",
      "}\n",
      "for (int k = 0; k < K; k++) {\n",
      "  for (int i = 0; i < 1; i++) {\n",
      "    __m512 A_vec;\n",
      "    (A_vec) = _mm512_set1_ps(A.data[(i) * (A.strides[0]) + (k) * (A.strides[1])]);\n",
      "    for (int jo = 0; jo < 4; jo++) {\n",
      "      __m512 B_vec;\n",
      "      B_vec = _mm512_loadu_ps(&B.data[(k) * (B.strides[0]) + (16 * jo) * (B.strides[1])]);\n",
      "      C_reg[i][jo] = _mm512_fmadd_ps((A_vec), (B_vec), C_reg[i][jo]);\n",
      "    }\n",
      "  }\n",
      "}\n",
      "for (int i = 0; i < 1; i++) {\n",
      "  for (int jo = 0; jo < 4; jo++) {\n",
      "    _mm512_storeu_ps(&C.data[(i) * (C.strides[0]) + (16 * jo) * (C.strides[1])], C_reg[i][jo]);\n",
      "  }\n",
      "}\n",
      "}\n",
      "\n",
      "// sgemm_kernel_avx512_2x4(\n",
      "//     K : size,\n",
      "//     A : [f32][2,K]  @DRAM,\n",
      "//     B : [f32][K,64]  @DRAM,\n",
      "//     C : [f32][2,64]  @DRAM\n",
      "// )\n",
      "void sgemm_kernel_avx512_2x4( c_code_str_Context *ctxt, int_fast32_t K, struct exo_win_2f32 A, struct exo_win_2f32 B, struct exo_win_2f32 C ) {\n",
      "EXO_ASSUME(K >= 1);\n",
      "EXO_ASSUME(A.strides[1] == 1);\n",
      "EXO_ASSUME(B.strides[1] == 1);\n",
      "EXO_ASSUME(C.strides[1] == 1);\n",
      "__m512 C_reg[2][4];\n",
      "for (int i = 0; i < 2; i++) {\n",
      "  for (int jo = 0; jo < 4; jo++) {\n",
      "    C_reg[i][jo] = _mm512_loadu_ps(&C.data[(i) * (C.strides[0]) + (16 * jo) * (C.strides[1])]);\n",
      "  }\n",
      "}\n",
      "for (int k = 0; k < K; k++) {\n",
      "  for (int i = 0; i < 2; i++) {\n",
      "    __m512 A_vec;\n",
      "    (A_vec) = _mm512_set1_ps(A.data[(i) * (A.strides[0]) + (k) * (A.strides[1])]);\n",
      "    for (int jo = 0; jo < 4; jo++) {\n",
      "      __m512 B_vec;\n",
      "      B_vec = _mm512_loadu_ps(&B.data[(k) * (B.strides[0]) + (16 * jo) * (B.strides[1])]);\n",
      "      C_reg[i][jo] = _mm512_fmadd_ps((A_vec), (B_vec), C_reg[i][jo]);\n",
      "    }\n",
      "  }\n",
      "}\n",
      "for (int i = 0; i < 2; i++) {\n",
      "  for (int jo = 0; jo < 4; jo++) {\n",
      "    _mm512_storeu_ps(&C.data[(i) * (C.strides[0]) + (16 * jo) * (C.strides[1])], C_reg[i][jo]);\n",
      "  }\n",
      "}\n",
      "}\n",
      "\n",
      "// sgemm_kernel_avx512_5x4(\n",
      "//     K : size,\n",
      "//     A : [f32][5,K]  @DRAM,\n",
      "//     B : [f32][K,64]  @DRAM,\n",
      "//     C : [f32][5,64]  @DRAM\n",
      "// )\n",
      "void sgemm_kernel_avx512_5x4( c_code_str_Context *ctxt, int_fast32_t K, struct exo_win_2f32 A, struct exo_win_2f32 B, struct exo_win_2f32 C ) {\n",
      "EXO_ASSUME(K >= 1);\n",
      "EXO_ASSUME(A.strides[1] == 1);\n",
      "EXO_ASSUME(B.strides[1] == 1);\n",
      "EXO_ASSUME(C.strides[1] == 1);\n",
      "__m512 C_reg[5][4];\n",
      "for (int i = 0; i < 5; i++) {\n",
      "  for (int jo = 0; jo < 4; jo++) {\n",
      "    C_reg[i][jo] = _mm512_loadu_ps(&C.data[(i) * (C.strides[0]) + (16 * jo) * (C.strides[1])]);\n",
      "  }\n",
      "}\n",
      "for (int k = 0; k < K; k++) {\n",
      "  for (int i = 0; i < 5; i++) {\n",
      "    __m512 A_vec;\n",
      "    (A_vec) = _mm512_set1_ps(A.data[(i) * (A.strides[0]) + (k) * (A.strides[1])]);\n",
      "    for (int jo = 0; jo < 4; jo++) {\n",
      "      __m512 B_vec;\n",
      "      B_vec = _mm512_loadu_ps(&B.data[(k) * (B.strides[0]) + (16 * jo) * (B.strides[1])]);\n",
      "      C_reg[i][jo] = _mm512_fmadd_ps((A_vec), (B_vec), C_reg[i][jo]);\n",
      "    }\n",
      "  }\n",
      "}\n",
      "for (int i = 0; i < 5; i++) {\n",
      "  for (int jo = 0; jo < 4; jo++) {\n",
      "    _mm512_storeu_ps(&C.data[(i) * (C.strides[0]) + (16 * jo) * (C.strides[1])], C_reg[i][jo]);\n",
      "  }\n",
      "}\n",
      "}\n",
      "\n",
      "// bottom_panel_kernel_scheduled(\n",
      "//     M : size,\n",
      "//     K : size,\n",
      "//     A : [f32][M,K]  @DRAM,\n",
      "//     B : [f32][K,64]  @DRAM,\n",
      "//     C : [f32][M,64]  @DRAM\n",
      "// )\n",
      "void bottom_panel_kernel_scheduled( c_code_str_Context *ctxt, int_fast32_t M, int_fast32_t K, struct exo_win_2f32 A, struct exo_win_2f32 B, struct exo_win_2f32 C ) {\n",
      "EXO_ASSUME(M >= 1);\n",
      "EXO_ASSUME(K >= 1);\n",
      "EXO_ASSUME(A.strides[1] == 1);\n",
      "EXO_ASSUME(B.strides[1] == 1);\n",
      "EXO_ASSUME(C.strides[1] == 1);\n",
      "EXO_ASSUME(M < 6);\n",
      "if (M == 1) {\n",
      "  sgemm_kernel_avx512_1x4(ctxt,K,(struct exo_win_2f32){ (float*)&A.data[(0) * (A.strides[0]) + (0) * (A.strides[1])], { A.strides[0], A.strides[1] } },(struct exo_win_2f32){ (float*)&B.data[(0) * (B.strides[0]) + (0) * (B.strides[1])], { B.strides[0], B.strides[1] } },(struct exo_win_2f32){ (float*)&C.data[(0) * (C.strides[0]) + (0) * (C.strides[1])], { C.strides[0], C.strides[1] } });\n",
      "} else {\n",
      "  if (M == 2) {\n",
      "    sgemm_kernel_avx512_2x4(ctxt,K,(struct exo_win_2f32){ (float*)&A.data[(0) * (A.strides[0]) + (0) * (A.strides[1])], { A.strides[0], A.strides[1] } },(struct exo_win_2f32){ (float*)&B.data[(0) * (B.strides[0]) + (0) * (B.strides[1])], { B.strides[0], B.strides[1] } },(struct exo_win_2f32){ (float*)&C.data[(0) * (C.strides[0]) + (0) * (C.strides[1])], { C.strides[0], C.strides[1] } });\n",
      "  } else {\n",
      "    if (M == 3) {\n",
      "      sgemm_kernel_avx512_3x4(ctxt,K,(struct exo_win_2f32){ (float*)&A.data[(0) * (A.strides[0]) + (0) * (A.strides[1])], { A.strides[0], A.strides[1] } },(struct exo_win_2f32){ (float*)&B.data[(0) * (B.strides[0]) + (0) * (B.strides[1])], { B.strides[0], B.strides[1] } },(struct exo_win_2f32){ (float*)&C.data[(0) * (C.strides[0]) + (0) * (C.strides[1])], { C.strides[0], C.strides[1] } });\n",
      "    } else {\n",
      "      if (M == 4) {\n",
      "        sgemm_kernel_avx512_4x4(ctxt,K,(struct exo_win_2f32){ (float*)&A.data[(0) * (A.strides[0]) + (0) * (A.strides[1])], { A.strides[0], A.strides[1] } },(struct exo_win_2f32){ (float*)&B.data[(0) * (B.strides[0]) + (0) * (B.strides[1])], { B.strides[0], B.strides[1] } },(struct exo_win_2f32){ (float*)&C.data[(0) * (C.strides[0]) + (0) * (C.strides[1])], { C.strides[0], C.strides[1] } });\n",
      "      } else {\n",
      "        if (M == 5) {\n",
      "          sgemm_kernel_avx512_5x4(ctxt,K,(struct exo_win_2f32){ (float*)&A.data[(0) * (A.strides[0]) + (0) * (A.strides[1])], { A.strides[0], A.strides[1] } },(struct exo_win_2f32){ (float*)&B.data[(0) * (B.strides[0]) + (0) * (B.strides[1])], { B.strides[0], B.strides[1] } },(struct exo_win_2f32){ (float*)&C.data[(0) * (C.strides[0]) + (0) * (C.strides[1])], { C.strides[0], C.strides[1] } });\n",
      "        } else {\n",
      "          for (int k = 0; k < K; k++) {\n",
      "            for (int i = 0; i < M; i++) {\n",
      "              for (int j = 0; j < 64; j++) {\n",
      "                C.data[(i) * (C.strides[0]) + (j) * (C.strides[1])] += A.data[(i) * (A.strides[0]) + (k) * (A.strides[1])] * B.data[(k) * (B.strides[0]) + (j) * (B.strides[1])];\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "}\n",
      "\n",
      "\n",
      "/* relying on the following instruction...\n",
      "mm512_storeu_ps(dst,src)\n",
      "_mm512_storeu_ps(&{dst_data}, {src_data});\n",
      "*/\n",
      "\n",
      "\n",
      "/* relying on the following instruction...\n",
      "mm512_set1_ps(dst,src)\n",
      "{dst} = _mm512_set1_ps({src_data});\n",
      "*/\n",
      "\n",
      "\n",
      "/* relying on the following instruction...\n",
      "mm512_fmadd_ps(A,B,C)\n",
      "{C_data} = _mm512_fmadd_ps({A}, {B}, {C_data});\n",
      "*/\n",
      "\n",
      "\n",
      "/* relying on the following instruction...\n",
      "mm512_loadu_ps(dst,src)\n",
      "{dst_data} = _mm512_loadu_ps(&{src_data});\n",
      "*/\n",
      "\n",
      "// sgemm_kernel_avx512_6x4(\n",
      "//     K : size,\n",
      "//     A : [f32][6,K]  @DRAM,\n",
      "//     B : [f32][K,64]  @DRAM,\n",
      "//     C : [f32][6,64]  @DRAM\n",
      "// )\n",
      "void sgemm_kernel_avx512_6x4( c_code_str_Context *ctxt, int_fast32_t K, struct exo_win_2f32 A, struct exo_win_2f32 B, struct exo_win_2f32 C ) {\n",
      "EXO_ASSUME(K >= 1);\n",
      "EXO_ASSUME(A.strides[1] == 1);\n",
      "EXO_ASSUME(B.strides[1] == 1);\n",
      "EXO_ASSUME(C.strides[1] == 1);\n",
      "__m512 C_reg[6][4];\n",
      "for (int i = 0; i < 6; i++) {\n",
      "  for (int jo = 0; jo < 4; jo++) {\n",
      "    C_reg[i][jo] = _mm512_loadu_ps(&C.data[(i) * (C.strides[0]) + (16 * jo) * (C.strides[1])]);\n",
      "  }\n",
      "}\n",
      "for (int k = 0; k < K; k++) {\n",
      "  for (int i = 0; i < 6; i++) {\n",
      "    __m512 A_vec;\n",
      "    (A_vec) = _mm512_set1_ps(A.data[(i) * (A.strides[0]) + (k) * (A.strides[1])]);\n",
      "    for (int jo = 0; jo < 4; jo++) {\n",
      "      __m512 B_vec;\n",
      "      B_vec = _mm512_loadu_ps(&B.data[(k) * (B.strides[0]) + (16 * jo) * (B.strides[1])]);\n",
      "      C_reg[i][jo] = _mm512_fmadd_ps((A_vec), (B_vec), C_reg[i][jo]);\n",
      "    }\n",
      "  }\n",
      "}\n",
      "for (int i = 0; i < 6; i++) {\n",
      "  for (int jo = 0; jo < 4; jo++) {\n",
      "    _mm512_storeu_ps(&C.data[(i) * (C.strides[0]) + (16 * jo) * (C.strides[1])], C_reg[i][jo]);\n",
      "  }\n",
      "}\n",
      "}\n",
      "\n",
      "// sgemm_above_kernel(\n",
      "//     M : size,\n",
      "//     N : size,\n",
      "//     K : size,\n",
      "//     A : [f32][M,K]  @DRAM,\n",
      "//     B : [f32][K,N]  @DRAM,\n",
      "//     C : [f32][M,N]  @DRAM\n",
      "// )\n",
      "void sgemm_above_kernel( c_code_str_Context *ctxt, int_fast32_t M, int_fast32_t N, int_fast32_t K, struct exo_win_2f32 A, struct exo_win_2f32 B, struct exo_win_2f32 C ) {\n",
      "EXO_ASSUME(M >= 1);\n",
      "EXO_ASSUME(N >= 1);\n",
      "EXO_ASSUME(K >= 1);\n",
      "EXO_ASSUME(A.strides[1] == 1);\n",
      "EXO_ASSUME(B.strides[1] == 1);\n",
      "EXO_ASSUME(C.strides[1] == 1);\n",
      "for (int io = 0; io < ((M) / (6)); io++) {\n",
      "  for (int jo = 0; jo < ((N) / (64)); jo++) {\n",
      "    sgemm_kernel_avx512_6x4(ctxt,K,(struct exo_win_2f32){ (float*)&A.data[(6 * io) * (A.strides[0]) + (0) * (A.strides[1])], { A.strides[0], A.strides[1] } },(struct exo_win_2f32){ (float*)&B.data[(0) * (B.strides[0]) + (64 * jo) * (B.strides[1])], { B.strides[0], B.strides[1] } },(struct exo_win_2f32){ (float*)&C.data[(6 * io) * (C.strides[0]) + (64 * jo) * (C.strides[1])], { C.strides[0], C.strides[1] } });\n",
      "  }\n",
      "}\n",
      "if (N % 64 > 0) {\n",
      "  for (int io = 0; io < ((M) / (6)); io++) {\n",
      "    right_panel_kernel_scheduled(ctxt,N % 64,K,(struct exo_win_2f32){ (float*)&A.data[(6 * io) * (A.strides[0]) + (0) * (A.strides[1])], { A.strides[0], A.strides[1] } },(struct exo_win_2f32){ (float*)&B.data[(0) * (B.strides[0]) + (64 * ((N) / (64))) * (B.strides[1])], { B.strides[0], B.strides[1] } },(struct exo_win_2f32){ (float*)&C.data[(6 * io) * (C.strides[0]) + (64 * ((N) / (64))) * (C.strides[1])], { C.strides[0], C.strides[1] } });\n",
      "  }\n",
      "}\n",
      "if (M % 6 > 0) {\n",
      "  for (int jo = 0; jo < ((N) / (64)); jo++) {\n",
      "    bottom_panel_kernel_scheduled(ctxt,M % 6,K,(struct exo_win_2f32){ (float*)&A.data[(6 * ((M) / (6))) * (A.strides[0]) + (0) * (A.strides[1])], { A.strides[0], A.strides[1] } },(struct exo_win_2f32){ (float*)&B.data[(0) * (B.strides[0]) + (64 * jo) * (B.strides[1])], { B.strides[0], B.strides[1] } },(struct exo_win_2f32){ (float*)&C.data[(6 * ((M) / (6))) * (C.strides[0]) + (64 * jo) * (C.strides[1])], { C.strides[0], C.strides[1] } });\n",
      "  }\n",
      "  if (N % 64 > 0) {\n",
      "    for (int k = 0; k < K; k++) {\n",
      "      for (int ii = 0; ii < M % 6; ii++) {\n",
      "        for (int ji = 0; ji < N % 64; ji++) {\n",
      "          C.data[(ii + ((M) / (6)) * 6) * (C.strides[0]) + (ji + ((N) / (64)) * 64) * (C.strides[1])] += A.data[(ii + ((M) / (6)) * 6) * (A.strides[0]) + (k) * (A.strides[1])] * B.data[(k) * (B.strides[0]) + (ji + ((N) / (64)) * 64) * (B.strides[1])];\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#calls either the microkernel, bottom_panel, or right_panel depending on whether or not the register sizes evenly divide the block sizes.\n",
    "sgemm_above_kernel = (\n",
    "    SGEMM_WINDOW\n",
    "        .rename('sgemm_above_kernel')\n",
    "        # Split up into cases\n",
    "        .split('j', N_REG_BLK, ['jo', 'ji'], tail='cut_and_guard')\n",
    "        .split('i', M_REG_BLK, ['io', 'ii'], tail='cut_and_guard')\n",
    "        .fission_after('for jo in _: _ #0', n_lifts=2)\n",
    "        .reorder('ii #0', 'jo')\n",
    "        .fission_after('for io in _: _')\n",
    "        .reorder('k #0', 'io')\n",
    "        .reorder('k #0', 'jo')\n",
    "        .lift_if('if N % _ > 0: _ #0', n_lifts=3)\n",
    "        .reorder('k', 'io')\n",
    "        .lift_if('if M % _ > 0: _ #0')\n",
    "        .fission_after('for jo in _: _ #1', n_lifts=2)\n",
    "        .reorder('ii', 'jo')\n",
    "        .reorder('k', 'jo')\n",
    "        .lift_if('if N % _ > 0: _ #1', n_lifts=2)\n",
    "        # Main block\n",
    "        .replace_all(basic_kernel_Mx4[6])\n",
    "        .call_eqv(sgemm_kernel_avx512_Mx4[6], 'basic_kernel_6x4(_)')\n",
    "        # Right panel\n",
    "        .replace_all(right_panel_kernel)\n",
    "        .call_eqv(right_panel_kernel_scheduled, 'right_panel_kernel(_)')\n",
    "        # Bottom panel\n",
    "        .replace_all(bottom_panel_kernel)\n",
    "        .call_eqv(bottom_panel_kernel_scheduled, 'bottom_panel_kernel(_)')\n",
    "        # TODO: bottom-right tile\n",
    "        .simplify()\n",
    ")\n",
    "print(sgemm_above_kernel.c_code_str())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#include <stdint.h>\n",
      "#include <stdbool.h>\n",
      "\n",
      "// Compiler feature macros adapted from Hedley (public domain)\n",
      "// https://github.com/nemequ/hedley\n",
      "\n",
      "#if defined(__has_builtin)\n",
      "#  define EXO_HAS_BUILTIN(builtin) __has_builtin(builtin)\n",
      "#else\n",
      "#  define EXO_HAS_BUILTIN(builtin) (0)\n",
      "#endif\n",
      "\n",
      "#if EXO_HAS_BUILTIN(__builtin_assume)\n",
      "#  define EXO_ASSUME(expr) __builtin_assume(expr)\n",
      "#elif EXO_HAS_BUILTIN(__builtin_unreachable)\n",
      "#  define EXO_ASSUME(expr) \\\n",
      "      ((void)((expr) ? 1 : (__builtin_unreachable(), 1)))\n",
      "#else\n",
      "#  define EXO_ASSUME(expr) ((void)(expr))\n",
      "#endif\n",
      "\n",
      "struct exo_win_2f32{\n",
      "    float *data;\n",
      "    int_fast32_t strides[2];\n",
      "};\n",
      "struct exo_win_1f32{\n",
      "    float *data;\n",
      "    int_fast32_t strides[1];\n",
      "};\n",
      "typedef struct c_code_str_Context { \n",
      "\n",
      "} c_code_str_Context;\n",
      "\n",
      "\n",
      "// sgemm_exo(\n",
      "//     M : size,\n",
      "//     N : size,\n",
      "//     K : size,\n",
      "//     A : f32[M,K]  @DRAM,\n",
      "//     B : f32[K,N]  @DRAM,\n",
      "//     C : f32[M,N]  @DRAM\n",
      "// )\n",
      "void sgemm_exo( c_code_str_Context *ctxt, int_fast32_t M, int_fast32_t N, int_fast32_t K, float* A, float* B, float* C );\n",
      "\n",
      "\n",
      "static int _floor_div(int num, int quot) {\n",
      "  int off = (num>=0)? 0 : quot-1;\n",
      "  return (num-off)/quot;\n",
      "}\n",
      "\n",
      "static int8_t _clamp_32to8(int32_t x) {\n",
      "  return (x < -128)? -128 : ((x > 127)? 127 : x);\n",
      "}\n",
      "\n",
      "#include <stdio.h>\n",
      "#include <stdlib.h>\n",
      "\n",
      "\n",
      "#include <immintrin.h>\n",
      "\n",
      "#include <stdio.h>\n",
      "#include <stdlib.h>\n",
      "\n",
      "\n",
      "// right_panel_kernel(\n",
      "//     N : size,\n",
      "//     K : size,\n",
      "//     A : [f32][6,K]  @DRAM,\n",
      "//     B : [f32][K,N]  @DRAM,\n",
      "//     C : [f32][6,N]  @DRAM\n",
      "// )\n",
      "void right_panel_kernel( c_code_str_Context *ctxt, int_fast32_t N, int_fast32_t K, struct exo_win_2f32 A, struct exo_win_2f32 B, struct exo_win_2f32 C ) {\n",
      "EXO_ASSUME(N >= 1);\n",
      "EXO_ASSUME(K >= 1);\n",
      "EXO_ASSUME(A.strides[1] == 1);\n",
      "EXO_ASSUME(B.strides[1] == 1);\n",
      "EXO_ASSUME(C.strides[1] == 1);\n",
      "EXO_ASSUME(((N) / (16)) < 4);\n",
      "for (int k = 0; k < K; k++) {\n",
      "  for (int i = 0; i < 6; i++) {\n",
      "    for (int j = 0; j < N; j++) {\n",
      "      C.data[(i) * (C.strides[0]) + (j) * (C.strides[1])] += A.data[(i) * (A.strides[0]) + (k) * (A.strides[1])] * B.data[(k) * (B.strides[0]) + (j) * (B.strides[1])];\n",
      "    }\n",
      "  }\n",
      "}\n",
      "}\n",
      "\n",
      "// right_panel_kernel_scheduled(\n",
      "//     N : size,\n",
      "//     K : size,\n",
      "//     A : [f32][6,K]  @DRAM,\n",
      "//     B : [f32][K,N]  @DRAM,\n",
      "//     C : [f32][6,N]  @DRAM\n",
      "// )\n",
      "void right_panel_kernel_scheduled( c_code_str_Context *ctxt, int_fast32_t N, int_fast32_t K, struct exo_win_2f32 A, struct exo_win_2f32 B, struct exo_win_2f32 C ) {\n",
      "EXO_ASSUME(N >= 1);\n",
      "EXO_ASSUME(K >= 1);\n",
      "EXO_ASSUME(A.strides[1] == 1);\n",
      "EXO_ASSUME(B.strides[1] == 1);\n",
      "EXO_ASSUME(C.strides[1] == 1);\n",
      "EXO_ASSUME(((N) / (16)) < 4);\n",
      "if (((N) / (16)) == 0) {\n",
      "  right_panel_kernel(ctxt,N,K,(struct exo_win_2f32){ (float*)&A.data[(0) * (A.strides[0]) + (0) * (A.strides[1])], { A.strides[0], A.strides[1] } },(struct exo_win_2f32){ (float*)&B.data[(0) * (B.strides[0]) + (0) * (B.strides[1])], { B.strides[0], B.strides[1] } },(struct exo_win_2f32){ (float*)&C.data[(0) * (C.strides[0]) + (0) * (C.strides[1])], { C.strides[0], C.strides[1] } });\n",
      "} else {\n",
      "  if (((N) / (16)) == 1) {\n",
      "    right_panel_kernel(ctxt,N,K,(struct exo_win_2f32){ (float*)&A.data[(0) * (A.strides[0]) + (0) * (A.strides[1])], { A.strides[0], A.strides[1] } },(struct exo_win_2f32){ (float*)&B.data[(0) * (B.strides[0]) + (0) * (B.strides[1])], { B.strides[0], B.strides[1] } },(struct exo_win_2f32){ (float*)&C.data[(0) * (C.strides[0]) + (0) * (C.strides[1])], { C.strides[0], C.strides[1] } });\n",
      "  } else {\n",
      "    if (((N) / (16)) == 2) {\n",
      "      right_panel_kernel(ctxt,N,K,(struct exo_win_2f32){ (float*)&A.data[(0) * (A.strides[0]) + (0) * (A.strides[1])], { A.strides[0], A.strides[1] } },(struct exo_win_2f32){ (float*)&B.data[(0) * (B.strides[0]) + (0) * (B.strides[1])], { B.strides[0], B.strides[1] } },(struct exo_win_2f32){ (float*)&C.data[(0) * (C.strides[0]) + (0) * (C.strides[1])], { C.strides[0], C.strides[1] } });\n",
      "    } else {\n",
      "      if (((N) / (16)) == 3) {\n",
      "        right_panel_kernel(ctxt,N,K,(struct exo_win_2f32){ (float*)&A.data[(0) * (A.strides[0]) + (0) * (A.strides[1])], { A.strides[0], A.strides[1] } },(struct exo_win_2f32){ (float*)&B.data[(0) * (B.strides[0]) + (0) * (B.strides[1])], { B.strides[0], B.strides[1] } },(struct exo_win_2f32){ (float*)&C.data[(0) * (C.strides[0]) + (0) * (C.strides[1])], { C.strides[0], C.strides[1] } });\n",
      "      } else {\n",
      "        right_panel_kernel(ctxt,N,K,(struct exo_win_2f32){ (float*)&A.data[(0) * (A.strides[0]) + (0) * (A.strides[1])], { A.strides[0], A.strides[1] } },(struct exo_win_2f32){ (float*)&B.data[(0) * (B.strides[0]) + (0) * (B.strides[1])], { B.strides[0], B.strides[1] } },(struct exo_win_2f32){ (float*)&C.data[(0) * (C.strides[0]) + (0) * (C.strides[1])], { C.strides[0], C.strides[1] } });\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "}\n",
      "\n",
      "// sgemm_kernel_avx512_4x4(\n",
      "//     K : size,\n",
      "//     A : [f32][4,K]  @DRAM,\n",
      "//     B : [f32][K,64]  @DRAM,\n",
      "//     C : [f32][4,64]  @DRAM\n",
      "// )\n",
      "void sgemm_kernel_avx512_4x4( c_code_str_Context *ctxt, int_fast32_t K, struct exo_win_2f32 A, struct exo_win_2f32 B, struct exo_win_2f32 C ) {\n",
      "EXO_ASSUME(K >= 1);\n",
      "EXO_ASSUME(A.strides[1] == 1);\n",
      "EXO_ASSUME(B.strides[1] == 1);\n",
      "EXO_ASSUME(C.strides[1] == 1);\n",
      "__m512 C_reg[4][4];\n",
      "for (int i = 0; i < 4; i++) {\n",
      "  for (int jo = 0; jo < 4; jo++) {\n",
      "    C_reg[i][jo] = _mm512_loadu_ps(&C.data[(i) * (C.strides[0]) + (16 * jo) * (C.strides[1])]);\n",
      "  }\n",
      "}\n",
      "for (int k = 0; k < K; k++) {\n",
      "  for (int i = 0; i < 4; i++) {\n",
      "    __m512 A_vec;\n",
      "    (A_vec) = _mm512_set1_ps(A.data[(i) * (A.strides[0]) + (k) * (A.strides[1])]);\n",
      "    for (int jo = 0; jo < 4; jo++) {\n",
      "      __m512 B_vec;\n",
      "      B_vec = _mm512_loadu_ps(&B.data[(k) * (B.strides[0]) + (16 * jo) * (B.strides[1])]);\n",
      "      C_reg[i][jo] = _mm512_fmadd_ps((A_vec), (B_vec), C_reg[i][jo]);\n",
      "    }\n",
      "  }\n",
      "}\n",
      "for (int i = 0; i < 4; i++) {\n",
      "  for (int jo = 0; jo < 4; jo++) {\n",
      "    _mm512_storeu_ps(&C.data[(i) * (C.strides[0]) + (16 * jo) * (C.strides[1])], C_reg[i][jo]);\n",
      "  }\n",
      "}\n",
      "}\n",
      "\n",
      "// sgemm_kernel_avx512_3x4(\n",
      "//     K : size,\n",
      "//     A : [f32][3,K]  @DRAM,\n",
      "//     B : [f32][K,64]  @DRAM,\n",
      "//     C : [f32][3,64]  @DRAM\n",
      "// )\n",
      "void sgemm_kernel_avx512_3x4( c_code_str_Context *ctxt, int_fast32_t K, struct exo_win_2f32 A, struct exo_win_2f32 B, struct exo_win_2f32 C ) {\n",
      "EXO_ASSUME(K >= 1);\n",
      "EXO_ASSUME(A.strides[1] == 1);\n",
      "EXO_ASSUME(B.strides[1] == 1);\n",
      "EXO_ASSUME(C.strides[1] == 1);\n",
      "__m512 C_reg[3][4];\n",
      "for (int i = 0; i < 3; i++) {\n",
      "  for (int jo = 0; jo < 4; jo++) {\n",
      "    C_reg[i][jo] = _mm512_loadu_ps(&C.data[(i) * (C.strides[0]) + (16 * jo) * (C.strides[1])]);\n",
      "  }\n",
      "}\n",
      "for (int k = 0; k < K; k++) {\n",
      "  for (int i = 0; i < 3; i++) {\n",
      "    __m512 A_vec;\n",
      "    (A_vec) = _mm512_set1_ps(A.data[(i) * (A.strides[0]) + (k) * (A.strides[1])]);\n",
      "    for (int jo = 0; jo < 4; jo++) {\n",
      "      __m512 B_vec;\n",
      "      B_vec = _mm512_loadu_ps(&B.data[(k) * (B.strides[0]) + (16 * jo) * (B.strides[1])]);\n",
      "      C_reg[i][jo] = _mm512_fmadd_ps((A_vec), (B_vec), C_reg[i][jo]);\n",
      "    }\n",
      "  }\n",
      "}\n",
      "for (int i = 0; i < 3; i++) {\n",
      "  for (int jo = 0; jo < 4; jo++) {\n",
      "    _mm512_storeu_ps(&C.data[(i) * (C.strides[0]) + (16 * jo) * (C.strides[1])], C_reg[i][jo]);\n",
      "  }\n",
      "}\n",
      "}\n",
      "\n",
      "// sgemm_kernel_avx512_1x4(\n",
      "//     K : size,\n",
      "//     A : [f32][1,K]  @DRAM,\n",
      "//     B : [f32][K,64]  @DRAM,\n",
      "//     C : [f32][1,64]  @DRAM\n",
      "// )\n",
      "void sgemm_kernel_avx512_1x4( c_code_str_Context *ctxt, int_fast32_t K, struct exo_win_2f32 A, struct exo_win_2f32 B, struct exo_win_2f32 C ) {\n",
      "EXO_ASSUME(K >= 1);\n",
      "EXO_ASSUME(A.strides[1] == 1);\n",
      "EXO_ASSUME(B.strides[1] == 1);\n",
      "EXO_ASSUME(C.strides[1] == 1);\n",
      "__m512 C_reg[1][4];\n",
      "for (int i = 0; i < 1; i++) {\n",
      "  for (int jo = 0; jo < 4; jo++) {\n",
      "    C_reg[i][jo] = _mm512_loadu_ps(&C.data[(i) * (C.strides[0]) + (16 * jo) * (C.strides[1])]);\n",
      "  }\n",
      "}\n",
      "for (int k = 0; k < K; k++) {\n",
      "  for (int i = 0; i < 1; i++) {\n",
      "    __m512 A_vec;\n",
      "    (A_vec) = _mm512_set1_ps(A.data[(i) * (A.strides[0]) + (k) * (A.strides[1])]);\n",
      "    for (int jo = 0; jo < 4; jo++) {\n",
      "      __m512 B_vec;\n",
      "      B_vec = _mm512_loadu_ps(&B.data[(k) * (B.strides[0]) + (16 * jo) * (B.strides[1])]);\n",
      "      C_reg[i][jo] = _mm512_fmadd_ps((A_vec), (B_vec), C_reg[i][jo]);\n",
      "    }\n",
      "  }\n",
      "}\n",
      "for (int i = 0; i < 1; i++) {\n",
      "  for (int jo = 0; jo < 4; jo++) {\n",
      "    _mm512_storeu_ps(&C.data[(i) * (C.strides[0]) + (16 * jo) * (C.strides[1])], C_reg[i][jo]);\n",
      "  }\n",
      "}\n",
      "}\n",
      "\n",
      "// sgemm_kernel_avx512_2x4(\n",
      "//     K : size,\n",
      "//     A : [f32][2,K]  @DRAM,\n",
      "//     B : [f32][K,64]  @DRAM,\n",
      "//     C : [f32][2,64]  @DRAM\n",
      "// )\n",
      "void sgemm_kernel_avx512_2x4( c_code_str_Context *ctxt, int_fast32_t K, struct exo_win_2f32 A, struct exo_win_2f32 B, struct exo_win_2f32 C ) {\n",
      "EXO_ASSUME(K >= 1);\n",
      "EXO_ASSUME(A.strides[1] == 1);\n",
      "EXO_ASSUME(B.strides[1] == 1);\n",
      "EXO_ASSUME(C.strides[1] == 1);\n",
      "__m512 C_reg[2][4];\n",
      "for (int i = 0; i < 2; i++) {\n",
      "  for (int jo = 0; jo < 4; jo++) {\n",
      "    C_reg[i][jo] = _mm512_loadu_ps(&C.data[(i) * (C.strides[0]) + (16 * jo) * (C.strides[1])]);\n",
      "  }\n",
      "}\n",
      "for (int k = 0; k < K; k++) {\n",
      "  for (int i = 0; i < 2; i++) {\n",
      "    __m512 A_vec;\n",
      "    (A_vec) = _mm512_set1_ps(A.data[(i) * (A.strides[0]) + (k) * (A.strides[1])]);\n",
      "    for (int jo = 0; jo < 4; jo++) {\n",
      "      __m512 B_vec;\n",
      "      B_vec = _mm512_loadu_ps(&B.data[(k) * (B.strides[0]) + (16 * jo) * (B.strides[1])]);\n",
      "      C_reg[i][jo] = _mm512_fmadd_ps((A_vec), (B_vec), C_reg[i][jo]);\n",
      "    }\n",
      "  }\n",
      "}\n",
      "for (int i = 0; i < 2; i++) {\n",
      "  for (int jo = 0; jo < 4; jo++) {\n",
      "    _mm512_storeu_ps(&C.data[(i) * (C.strides[0]) + (16 * jo) * (C.strides[1])], C_reg[i][jo]);\n",
      "  }\n",
      "}\n",
      "}\n",
      "\n",
      "// sgemm_kernel_avx512_5x4(\n",
      "//     K : size,\n",
      "//     A : [f32][5,K]  @DRAM,\n",
      "//     B : [f32][K,64]  @DRAM,\n",
      "//     C : [f32][5,64]  @DRAM\n",
      "// )\n",
      "void sgemm_kernel_avx512_5x4( c_code_str_Context *ctxt, int_fast32_t K, struct exo_win_2f32 A, struct exo_win_2f32 B, struct exo_win_2f32 C ) {\n",
      "EXO_ASSUME(K >= 1);\n",
      "EXO_ASSUME(A.strides[1] == 1);\n",
      "EXO_ASSUME(B.strides[1] == 1);\n",
      "EXO_ASSUME(C.strides[1] == 1);\n",
      "__m512 C_reg[5][4];\n",
      "for (int i = 0; i < 5; i++) {\n",
      "  for (int jo = 0; jo < 4; jo++) {\n",
      "    C_reg[i][jo] = _mm512_loadu_ps(&C.data[(i) * (C.strides[0]) + (16 * jo) * (C.strides[1])]);\n",
      "  }\n",
      "}\n",
      "for (int k = 0; k < K; k++) {\n",
      "  for (int i = 0; i < 5; i++) {\n",
      "    __m512 A_vec;\n",
      "    (A_vec) = _mm512_set1_ps(A.data[(i) * (A.strides[0]) + (k) * (A.strides[1])]);\n",
      "    for (int jo = 0; jo < 4; jo++) {\n",
      "      __m512 B_vec;\n",
      "      B_vec = _mm512_loadu_ps(&B.data[(k) * (B.strides[0]) + (16 * jo) * (B.strides[1])]);\n",
      "      C_reg[i][jo] = _mm512_fmadd_ps((A_vec), (B_vec), C_reg[i][jo]);\n",
      "    }\n",
      "  }\n",
      "}\n",
      "for (int i = 0; i < 5; i++) {\n",
      "  for (int jo = 0; jo < 4; jo++) {\n",
      "    _mm512_storeu_ps(&C.data[(i) * (C.strides[0]) + (16 * jo) * (C.strides[1])], C_reg[i][jo]);\n",
      "  }\n",
      "}\n",
      "}\n",
      "\n",
      "// bottom_panel_kernel_scheduled(\n",
      "//     M : size,\n",
      "//     K : size,\n",
      "//     A : [f32][M,K]  @DRAM,\n",
      "//     B : [f32][K,64]  @DRAM,\n",
      "//     C : [f32][M,64]  @DRAM\n",
      "// )\n",
      "void bottom_panel_kernel_scheduled( c_code_str_Context *ctxt, int_fast32_t M, int_fast32_t K, struct exo_win_2f32 A, struct exo_win_2f32 B, struct exo_win_2f32 C ) {\n",
      "EXO_ASSUME(M >= 1);\n",
      "EXO_ASSUME(K >= 1);\n",
      "EXO_ASSUME(A.strides[1] == 1);\n",
      "EXO_ASSUME(B.strides[1] == 1);\n",
      "EXO_ASSUME(C.strides[1] == 1);\n",
      "EXO_ASSUME(M < 6);\n",
      "if (M == 1) {\n",
      "  sgemm_kernel_avx512_1x4(ctxt,K,(struct exo_win_2f32){ (float*)&A.data[(0) * (A.strides[0]) + (0) * (A.strides[1])], { A.strides[0], A.strides[1] } },(struct exo_win_2f32){ (float*)&B.data[(0) * (B.strides[0]) + (0) * (B.strides[1])], { B.strides[0], B.strides[1] } },(struct exo_win_2f32){ (float*)&C.data[(0) * (C.strides[0]) + (0) * (C.strides[1])], { C.strides[0], C.strides[1] } });\n",
      "} else {\n",
      "  if (M == 2) {\n",
      "    sgemm_kernel_avx512_2x4(ctxt,K,(struct exo_win_2f32){ (float*)&A.data[(0) * (A.strides[0]) + (0) * (A.strides[1])], { A.strides[0], A.strides[1] } },(struct exo_win_2f32){ (float*)&B.data[(0) * (B.strides[0]) + (0) * (B.strides[1])], { B.strides[0], B.strides[1] } },(struct exo_win_2f32){ (float*)&C.data[(0) * (C.strides[0]) + (0) * (C.strides[1])], { C.strides[0], C.strides[1] } });\n",
      "  } else {\n",
      "    if (M == 3) {\n",
      "      sgemm_kernel_avx512_3x4(ctxt,K,(struct exo_win_2f32){ (float*)&A.data[(0) * (A.strides[0]) + (0) * (A.strides[1])], { A.strides[0], A.strides[1] } },(struct exo_win_2f32){ (float*)&B.data[(0) * (B.strides[0]) + (0) * (B.strides[1])], { B.strides[0], B.strides[1] } },(struct exo_win_2f32){ (float*)&C.data[(0) * (C.strides[0]) + (0) * (C.strides[1])], { C.strides[0], C.strides[1] } });\n",
      "    } else {\n",
      "      if (M == 4) {\n",
      "        sgemm_kernel_avx512_4x4(ctxt,K,(struct exo_win_2f32){ (float*)&A.data[(0) * (A.strides[0]) + (0) * (A.strides[1])], { A.strides[0], A.strides[1] } },(struct exo_win_2f32){ (float*)&B.data[(0) * (B.strides[0]) + (0) * (B.strides[1])], { B.strides[0], B.strides[1] } },(struct exo_win_2f32){ (float*)&C.data[(0) * (C.strides[0]) + (0) * (C.strides[1])], { C.strides[0], C.strides[1] } });\n",
      "      } else {\n",
      "        if (M == 5) {\n",
      "          sgemm_kernel_avx512_5x4(ctxt,K,(struct exo_win_2f32){ (float*)&A.data[(0) * (A.strides[0]) + (0) * (A.strides[1])], { A.strides[0], A.strides[1] } },(struct exo_win_2f32){ (float*)&B.data[(0) * (B.strides[0]) + (0) * (B.strides[1])], { B.strides[0], B.strides[1] } },(struct exo_win_2f32){ (float*)&C.data[(0) * (C.strides[0]) + (0) * (C.strides[1])], { C.strides[0], C.strides[1] } });\n",
      "        } else {\n",
      "          for (int k = 0; k < K; k++) {\n",
      "            for (int i = 0; i < M; i++) {\n",
      "              for (int j = 0; j < 64; j++) {\n",
      "                C.data[(i) * (C.strides[0]) + (j) * (C.strides[1])] += A.data[(i) * (A.strides[0]) + (k) * (A.strides[1])] * B.data[(k) * (B.strides[0]) + (j) * (B.strides[1])];\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "}\n",
      "\n",
      "\n",
      "/* relying on the following instruction...\n",
      "mm512_storeu_ps(dst,src)\n",
      "_mm512_storeu_ps(&{dst_data}, {src_data});\n",
      "*/\n",
      "\n",
      "\n",
      "/* relying on the following instruction...\n",
      "mm512_set1_ps(dst,src)\n",
      "{dst} = _mm512_set1_ps({src_data});\n",
      "*/\n",
      "\n",
      "\n",
      "/* relying on the following instruction...\n",
      "mm512_fmadd_ps(A,B,C)\n",
      "{C_data} = _mm512_fmadd_ps({A}, {B}, {C_data});\n",
      "*/\n",
      "\n",
      "\n",
      "/* relying on the following instruction...\n",
      "mm512_loadu_ps(dst,src)\n",
      "{dst_data} = _mm512_loadu_ps(&{src_data});\n",
      "*/\n",
      "\n",
      "// sgemm_kernel_avx512_6x4(\n",
      "//     K : size,\n",
      "//     A : [f32][6,K]  @DRAM,\n",
      "//     B : [f32][K,64]  @DRAM,\n",
      "//     C : [f32][6,64]  @DRAM\n",
      "// )\n",
      "void sgemm_kernel_avx512_6x4( c_code_str_Context *ctxt, int_fast32_t K, struct exo_win_2f32 A, struct exo_win_2f32 B, struct exo_win_2f32 C ) {\n",
      "EXO_ASSUME(K >= 1);\n",
      "EXO_ASSUME(A.strides[1] == 1);\n",
      "EXO_ASSUME(B.strides[1] == 1);\n",
      "EXO_ASSUME(C.strides[1] == 1);\n",
      "__m512 C_reg[6][4];\n",
      "for (int i = 0; i < 6; i++) {\n",
      "  for (int jo = 0; jo < 4; jo++) {\n",
      "    C_reg[i][jo] = _mm512_loadu_ps(&C.data[(i) * (C.strides[0]) + (16 * jo) * (C.strides[1])]);\n",
      "  }\n",
      "}\n",
      "for (int k = 0; k < K; k++) {\n",
      "  for (int i = 0; i < 6; i++) {\n",
      "    __m512 A_vec;\n",
      "    (A_vec) = _mm512_set1_ps(A.data[(i) * (A.strides[0]) + (k) * (A.strides[1])]);\n",
      "    for (int jo = 0; jo < 4; jo++) {\n",
      "      __m512 B_vec;\n",
      "      B_vec = _mm512_loadu_ps(&B.data[(k) * (B.strides[0]) + (16 * jo) * (B.strides[1])]);\n",
      "      C_reg[i][jo] = _mm512_fmadd_ps((A_vec), (B_vec), C_reg[i][jo]);\n",
      "    }\n",
      "  }\n",
      "}\n",
      "for (int i = 0; i < 6; i++) {\n",
      "  for (int jo = 0; jo < 4; jo++) {\n",
      "    _mm512_storeu_ps(&C.data[(i) * (C.strides[0]) + (16 * jo) * (C.strides[1])], C_reg[i][jo]);\n",
      "  }\n",
      "}\n",
      "}\n",
      "\n",
      "// sgemm_above_kernel(\n",
      "//     M : size,\n",
      "//     N : size,\n",
      "//     K : size,\n",
      "//     A : [f32][M,K]  @DRAM,\n",
      "//     B : [f32][K,N]  @DRAM,\n",
      "//     C : [f32][M,N]  @DRAM\n",
      "// )\n",
      "void sgemm_above_kernel( c_code_str_Context *ctxt, int_fast32_t M, int_fast32_t N, int_fast32_t K, struct exo_win_2f32 A, struct exo_win_2f32 B, struct exo_win_2f32 C ) {\n",
      "EXO_ASSUME(M >= 1);\n",
      "EXO_ASSUME(N >= 1);\n",
      "EXO_ASSUME(K >= 1);\n",
      "EXO_ASSUME(A.strides[1] == 1);\n",
      "EXO_ASSUME(B.strides[1] == 1);\n",
      "EXO_ASSUME(C.strides[1] == 1);\n",
      "for (int io = 0; io < ((M) / (6)); io++) {\n",
      "  for (int jo = 0; jo < ((N) / (64)); jo++) {\n",
      "    sgemm_kernel_avx512_6x4(ctxt,K,(struct exo_win_2f32){ (float*)&A.data[(6 * io) * (A.strides[0]) + (0) * (A.strides[1])], { A.strides[0], A.strides[1] } },(struct exo_win_2f32){ (float*)&B.data[(0) * (B.strides[0]) + (64 * jo) * (B.strides[1])], { B.strides[0], B.strides[1] } },(struct exo_win_2f32){ (float*)&C.data[(6 * io) * (C.strides[0]) + (64 * jo) * (C.strides[1])], { C.strides[0], C.strides[1] } });\n",
      "  }\n",
      "}\n",
      "if (N % 64 > 0) {\n",
      "  for (int io = 0; io < ((M) / (6)); io++) {\n",
      "    right_panel_kernel_scheduled(ctxt,N % 64,K,(struct exo_win_2f32){ (float*)&A.data[(6 * io) * (A.strides[0]) + (0) * (A.strides[1])], { A.strides[0], A.strides[1] } },(struct exo_win_2f32){ (float*)&B.data[(0) * (B.strides[0]) + (64 * ((N) / (64))) * (B.strides[1])], { B.strides[0], B.strides[1] } },(struct exo_win_2f32){ (float*)&C.data[(6 * io) * (C.strides[0]) + (64 * ((N) / (64))) * (C.strides[1])], { C.strides[0], C.strides[1] } });\n",
      "  }\n",
      "}\n",
      "if (M % 6 > 0) {\n",
      "  for (int jo = 0; jo < ((N) / (64)); jo++) {\n",
      "    bottom_panel_kernel_scheduled(ctxt,M % 6,K,(struct exo_win_2f32){ (float*)&A.data[(6 * ((M) / (6))) * (A.strides[0]) + (0) * (A.strides[1])], { A.strides[0], A.strides[1] } },(struct exo_win_2f32){ (float*)&B.data[(0) * (B.strides[0]) + (64 * jo) * (B.strides[1])], { B.strides[0], B.strides[1] } },(struct exo_win_2f32){ (float*)&C.data[(6 * ((M) / (6))) * (C.strides[0]) + (64 * jo) * (C.strides[1])], { C.strides[0], C.strides[1] } });\n",
      "  }\n",
      "  if (N % 64 > 0) {\n",
      "    for (int k = 0; k < K; k++) {\n",
      "      for (int ii = 0; ii < M % 6; ii++) {\n",
      "        for (int ji = 0; ji < N % 64; ji++) {\n",
      "          C.data[(ii + ((M) / (6)) * 6) * (C.strides[0]) + (ji + ((N) / (64)) * 64) * (C.strides[1])] += A.data[(ii + ((M) / (6)) * 6) * (A.strides[0]) + (k) * (A.strides[1])] * B.data[(k) * (B.strides[0]) + (ji + ((N) / (64)) * 64) * (B.strides[1])];\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "}\n",
      "\n",
      "// sgemm_exo(\n",
      "//     M : size,\n",
      "//     N : size,\n",
      "//     K : size,\n",
      "//     A : f32[M,K]  @DRAM,\n",
      "//     B : f32[K,N]  @DRAM,\n",
      "//     C : f32[M,N]  @DRAM\n",
      "// )\n",
      "void sgemm_exo( c_code_str_Context *ctxt, int_fast32_t M, int_fast32_t N, int_fast32_t K, float* A, float* B, float* C ) {\n",
      "EXO_ASSUME(M >= 1);\n",
      "EXO_ASSUME(N >= 1);\n",
      "EXO_ASSUME(K >= 1);\n",
      "EXO_ASSUME(1 == 1);\n",
      "EXO_ASSUME(1 == 1);\n",
      "EXO_ASSUME(1 == 1);\n",
      "static float A1_cache[264 * 512];\n",
      "static float B1_cache[512 * 64];\n",
      "for (int ko = 0; ko < ((K) / (512)); ko++) {\n",
      "  for (int io = 0; io < ((M) / (264)); io++) {\n",
      "    for (int i0 = 0; i0 < 264; i0++) {\n",
      "      for (int i1 = 0; i1 < 512; i1++) {\n",
      "        A1_cache[(i0) * (512) + (i1) * (1)] = A[(264 * io + i0) * (K) + (512 * ko + i1) * (1)];\n",
      "      }\n",
      "    }\n",
      "    for (int jo = 0; jo < ((N) / (64)); jo++) {\n",
      "      for (int i0 = 0; i0 < 512; i0++) {\n",
      "        for (int i1 = 0; i1 < 64; i1++) {\n",
      "          B1_cache[(i0) * (64) + (i1) * (1)] = B[(512 * ko + i0) * (N) + (64 * jo + i1) * (1)];\n",
      "        }\n",
      "      }\n",
      "      sgemm_above_kernel(ctxt,264,64,512,(struct exo_win_2f32){ (float*)&A1_cache[(0) * (512) + (0) * (1)], { 512, 1 } },(struct exo_win_2f32){ (float*)&B1_cache[(0) * (64) + (0) * (1)], { 64, 1 } },(struct exo_win_2f32){ (float*)&C[(264 * io) * (N) + (64 * jo) * (1)], { N, 1 } });\n",
      "    }\n",
      "  }\n",
      "}\n",
      "if (N % 64 > 0) {\n",
      "  for (int ko = 0; ko < ((K) / (512)); ko++) {\n",
      "    static float B2_cache[512 * 64];\n",
      "    for (int i0 = 0; i0 < 512; i0++) {\n",
      "      for (int i1 = 0; i1 < N - 64 * ((N) / (64)); i1++) {\n",
      "        B2_cache[(i0) * (64) + (i1) * (1)] = B[(512 * ko + i0) * (N) + (64 * ((N) / (64)) + i1) * (1)];\n",
      "      }\n",
      "    }\n",
      "    for (int io = 0; io < ((M) / (264)); io++) {\n",
      "      sgemm_above_kernel(ctxt,264,N % 64,512,(struct exo_win_2f32){ (float*)&A[(264 * io) * (K) + (512 * ko) * (1)], { K, 1 } },(struct exo_win_2f32){ (float*)&B2_cache[(0) * (64) + (0) * (1)], { 64, 1 } },(struct exo_win_2f32){ (float*)&C[(264 * io) * (N) + (64 * ((N) / (64))) * (1)], { N, 1 } });\n",
      "    }\n",
      "  }\n",
      "}\n",
      "if (M % 264 > 0) {\n",
      "  for (int ko = 0; ko < ((K) / (512)); ko++) {\n",
      "    for (int jo = 0; jo < ((N) / (64)); jo++) {\n",
      "      static float B3_cache[512 * 64];\n",
      "      for (int i0 = 0; i0 < 512; i0++) {\n",
      "        for (int i1 = 0; i1 < 64; i1++) {\n",
      "          B3_cache[(i0) * (64) + (i1) * (1)] = B[(512 * ko + i0) * (N) + (64 * jo + i1) * (1)];\n",
      "        }\n",
      "      }\n",
      "      sgemm_above_kernel(ctxt,M % 264,64,512,(struct exo_win_2f32){ (float*)&A[(264 * ((M) / (264))) * (K) + (512 * ko) * (1)], { K, 1 } },(struct exo_win_2f32){ (float*)&B3_cache[(0) * (64) + (0) * (1)], { 64, 1 } },(struct exo_win_2f32){ (float*)&C[(264 * ((M) / (264))) * (N) + (64 * jo) * (1)], { N, 1 } });\n",
      "    }\n",
      "  }\n",
      "}\n",
      "if (M % 264 > 0) {\n",
      "  if (N % 64 > 0) {\n",
      "    for (int ko = 0; ko < ((K) / (512)); ko++) {\n",
      "      static float B4_cache[512 * 64];\n",
      "      for (int i0 = 0; i0 < 512; i0++) {\n",
      "        for (int i1 = 0; i1 < N - 64 * ((N) / (64)); i1++) {\n",
      "          B4_cache[(i0) * (64) + (i1) * (1)] = B[(512 * ko + i0) * (N) + (64 * ((N) / (64)) + i1) * (1)];\n",
      "        }\n",
      "      }\n",
      "      sgemm_above_kernel(ctxt,M % 264,N % 64,512,(struct exo_win_2f32){ (float*)&A[(264 * ((M) / (264))) * (K) + (512 * ko) * (1)], { K, 1 } },(struct exo_win_2f32){ (float*)&B4_cache[(0) * (64) + (0) * (1)], { 64, 1 } },(struct exo_win_2f32){ (float*)&C[(264 * ((M) / (264))) * (N) + (64 * ((N) / (64))) * (1)], { N, 1 } });\n",
      "    }\n",
      "  }\n",
      "}\n",
      "if (K % 512 > 0) {\n",
      "  for (int io = 0; io < ((M) / (264)); io++) {\n",
      "    for (int jo = 0; jo < ((N) / (64)); jo++) {\n",
      "      static float B5_cache[512 * 64];\n",
      "      for (int i0 = 0; i0 < K - 512 * ((K) / (512)); i0++) {\n",
      "        for (int i1 = 0; i1 < 64; i1++) {\n",
      "          B5_cache[(i0) * (64) + (i1) * (1)] = B[(512 * ((K) / (512)) + i0) * (N) + (64 * jo + i1) * (1)];\n",
      "        }\n",
      "      }\n",
      "      sgemm_above_kernel(ctxt,264,64,K % 512,(struct exo_win_2f32){ (float*)&A[(264 * io) * (K) + (512 * ((K) / (512))) * (1)], { K, 1 } },(struct exo_win_2f32){ (float*)&B5_cache[(0) * (64) + (0) * (1)], { 64, 1 } },(struct exo_win_2f32){ (float*)&C[(264 * io) * (N) + (64 * jo) * (1)], { N, 1 } });\n",
      "    }\n",
      "  }\n",
      "}\n",
      "if (K % 512 > 0) {\n",
      "  if (N % 64 > 0) {\n",
      "    for (int io = 0; io < ((M) / (264)); io++) {\n",
      "      static float B6_cache[512 * 64];\n",
      "      for (int i0 = 0; i0 < K - 512 * ((K) / (512)); i0++) {\n",
      "        for (int i1 = 0; i1 < N - 64 * ((N) / (64)); i1++) {\n",
      "          B6_cache[(i0) * (64) + (i1) * (1)] = B[(512 * ((K) / (512)) + i0) * (N) + (64 * ((N) / (64)) + i1) * (1)];\n",
      "        }\n",
      "      }\n",
      "      sgemm_above_kernel(ctxt,264,N % 64,K % 512,(struct exo_win_2f32){ (float*)&A[(264 * io) * (K) + (512 * ((K) / (512))) * (1)], { K, 1 } },(struct exo_win_2f32){ (float*)&B6_cache[(0) * (64) + (0) * (1)], { 64, 1 } },(struct exo_win_2f32){ (float*)&C[(264 * io) * (N) + (64 * ((N) / (64))) * (1)], { N, 1 } });\n",
      "    }\n",
      "  }\n",
      "}\n",
      "if (K % 512 > 0) {\n",
      "  if (M % 264 > 0) {\n",
      "    for (int jo = 0; jo < ((N) / (64)); jo++) {\n",
      "      static float B7_cache[512 * 64];\n",
      "      for (int i0 = 0; i0 < K - 512 * ((K) / (512)); i0++) {\n",
      "        for (int i1 = 0; i1 < 64; i1++) {\n",
      "          B7_cache[(i0) * (64) + (i1) * (1)] = B[(512 * ((K) / (512)) + i0) * (N) + (64 * jo + i1) * (1)];\n",
      "        }\n",
      "      }\n",
      "      sgemm_above_kernel(ctxt,M % 264,64,K % 512,(struct exo_win_2f32){ (float*)&A[(264 * ((M) / (264))) * (K) + (512 * ((K) / (512))) * (1)], { K, 1 } },(struct exo_win_2f32){ (float*)&B7_cache[(0) * (64) + (0) * (1)], { 64, 1 } },(struct exo_win_2f32){ (float*)&C[(264 * ((M) / (264))) * (N) + (64 * jo) * (1)], { N, 1 } });\n",
      "    }\n",
      "  }\n",
      "}\n",
      "if (K % 512 > 0) {\n",
      "  if (M % 264 > 0) {\n",
      "    if (N % 64 > 0) {\n",
      "      static float B8_cache[512 * 64];\n",
      "      for (int i0 = 0; i0 < K - 512 * ((K) / (512)); i0++) {\n",
      "        for (int i1 = 0; i1 < N - 64 * ((N) / (64)); i1++) {\n",
      "          B8_cache[(i0) * (64) + (i1) * (1)] = B[(512 * ((K) / (512)) + i0) * (N) + (64 * ((N) / (64)) + i1) * (1)];\n",
      "        }\n",
      "      }\n",
      "      sgemm_above_kernel(ctxt,M % 264,N % 64,K % 512,(struct exo_win_2f32){ (float*)&A[(264 * ((M) / (264))) * (K) + (512 * ((K) / (512))) * (1)], { K, 1 } },(struct exo_win_2f32){ (float*)&B8_cache[(0) * (64) + (0) * (1)], { 64, 1 } },(struct exo_win_2f32){ (float*)&C[(264 * ((M) / (264))) * (N) + (64 * ((N) / (64))) * (1)], { N, 1 } });\n",
      "    }\n",
      "  }\n",
      "}\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Handles blocking and all possible edge cases involving block size divisibility with the complete dimensions\n",
    "sgemm_exo = (\n",
    "    SGEMM\n",
    "        .rename('sgemm_exo')\n",
    "        # Split all loops\n",
    "        .split('k', K_L1_BLK, ['ko', 'ki'], tail='cut_and_guard')\n",
    "        .split('i', M_L1_BLK, ['io', 'ii'], tail='cut_and_guard')\n",
    "        .split('j', N_L1_BLK, ['jo', 'ji'], tail='cut_and_guard')\n",
    "        # Explode into 8 cases\n",
    "        .fission_after('for io in _: _', n_lifts=2)\n",
    "        .fission_after('for jo in _: _', n_lifts=4)\n",
    "        # Case 1:\n",
    "        .reorder('ki', 'io')\n",
    "        .reorder('ii', 'jo')\n",
    "        .reorder('ki', 'jo')\n",
    "        .replace(SGEMM_WINDOW, 'for ki in _: _ #0')\n",
    "        # Case 2:\n",
    "        .lift_if('if N % _ > 0: _ #0', n_lifts=4)\n",
    "        .replace(SGEMM_WINDOW, 'for ki in _: _ #0')\n",
    "        # Case 3:\n",
    "        .lift_if('if M % _ > 0: _ #0', n_lifts=2)\n",
    "        .reorder('ki', 'jo')\n",
    "        .replace(SGEMM_WINDOW, 'for ki in _: _ #0')\n",
    "        # Case 4:\n",
    "        .lift_if('if M % _ > 0: _ #1', n_lifts=2)\n",
    "        .lift_if('if N % _ > 0: _ #1', n_lifts=3)\n",
    "        .replace(SGEMM_WINDOW, 'for ki in _: _ #0')\n",
    "        # Case 5:\n",
    "        .replace(SGEMM_WINDOW, 'for ki in _: _ #0')\n",
    "        # Case 6:\n",
    "        .lift_if('if N % _ > 0: _ #2', n_lifts=3)\n",
    "        .replace(SGEMM_WINDOW, 'for ki in _: _ #0')\n",
    "        # Case 7:\n",
    "        .lift_if('if M % _ > 0: _ #2')\n",
    "        .reorder('ki', 'jo')\n",
    "        .replace(SGEMM_WINDOW, 'for ki in _: _ #0')\n",
    "        # Case 8:\n",
    "        .lift_if('if M % _ > 0: _ #3')\n",
    "        .lift_if('if N % _ > 0: _ #3', n_lifts=2)\n",
    "        .replace(SGEMM_WINDOW, 'for ki in _: _ #0')\n",
    "        ## Case 1 memory staging\n",
    "        .stage_window('A1_cache', 'A[_] #0', DRAM_STATIC)\n",
    "        .stage_window('B1_cache', 'B[_] #0', DRAM_STATIC)\n",
    "        .par_to_seq('for ko in _: _ #0')\n",
    "        .par_to_seq('for io in _: _ #0')\n",
    "        .par_to_seq('for jo in _: _ #0')\n",
    "        .lift_alloc('A1_cache: _', n_lifts=3)\n",
    "        .lift_alloc('B1_cache: _', n_lifts=3)\n",
    "        .fission_after('for i0 in _: _ #0')\n",
    "        ## Case 2 memory staging\n",
    "        .stage_window('B2_cache', 'B[_] #1', DRAM_STATIC)\n",
    "        .bound_alloc('B2_cache: _', [None, f'{N_L1_BLK}'])\n",
    "        .lift_alloc('B2_cache: _')\n",
    "        .fission_after('for i0 in _: _ #2')\n",
    "        ## Case 3 memory staging\n",
    "        .stage_window('B3_cache', 'B[_] #2', DRAM_STATIC)\n",
    "        ## Case 4 memory staging\n",
    "        .stage_window('B4_cache', 'B[_] #3', DRAM_STATIC)\n",
    "        .bound_alloc('B4_cache: _', [None, f'{N_L1_BLK}'])\n",
    "        ## Case 5 memory staging\n",
    "        .stage_window('B5_cache', 'B[_] #4', DRAM_STATIC)\n",
    "        .bound_alloc('B5_cache: _', [f'{K_L1_BLK}', None])\n",
    "        ## Case 6 memory staging\n",
    "        .stage_window('B6_cache', 'B[_] #5', DRAM_STATIC)\n",
    "        .bound_alloc('B6_cache: _', [f'{K_L1_BLK}', f'{N_L1_BLK}'])\n",
    "        # .lift_alloc('B6_cache: _')\n",
    "        # .fission_after('for i0 in _: _ #6')\n",
    "        ## Case 7 memory staging\n",
    "        .stage_window('B7_cache', 'B[_] #6', DRAM_STATIC)\n",
    "        .bound_alloc('B7_cache: _', [f'{K_L1_BLK}', None])\n",
    "        ## Case 8 memory staging\n",
    "        .stage_window('B8_cache', 'B[_] #7', DRAM_STATIC)\n",
    "        .bound_alloc('B8_cache: _', [f'{K_L1_BLK}', f'{N_L1_BLK}'])\n",
    "        ## Replace SGEMM_WINDOW with optimized form\n",
    "        # These must come AFTER bound_alloc since the internal check-effects\n",
    "        # is a whole program analysis that is VERY expensive\n",
    "        .repeat(Procedure.call_eqv, sgemm_above_kernel, 'SGEMM_WINDOW(_)')\n",
    "        # Clean up\n",
    "        .simplify()\n",
    ")\n",
    "print(sgemm_exo.c_code_str())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reorder(var1, var2)\n",
    "\n",
    "    swaps the positions of the #Nth occurance of VAR1 with VAR2\n",
    "\n",
    "lift_if(pattern, n_lifts)\n",
    "\n",
    "    moves the if statement matching PATTERN N_LIFTS brackets above its current location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cfcf57d6ae59e4d2bb98893a51e38ba5a7224cc175410b3cafee5a761b26a0c2"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('exo': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
